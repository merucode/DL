{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/01-colab-study_must_have_pytorch/14-%5Bgenerater-image-improvement%5D-SRGAN-basic--image-improvement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 0. Version check and Install Dependency"
      ],
      "metadata": {
        "id": "LxkMBWDW9T3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0-1. Version Check"
      ],
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ],
      "metadata": {
        "id": "pvZ7Lm3Apv1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0-2. Install Dependency"
      ],
      "metadata": {
        "id": "cNpk3WdHys1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export export KAGGLE_USERNAME=*** && export KAGGLE_KEY=*** && kaggle datasets download -d jessicali9530/celeba-dataset\n",
        "!unzip \"./celeba-dataset.zip\" -d \"./GAN/\""
      ],
      "metadata": {
        "id": "ye2JDNesCfAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1. Check Data"
      ],
      "metadata": {
        "id": "TquybxQaqfE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-1. Load data"
      ],
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# 이미지까지의 경로\n",
        "pth_to_imgs = \"./GAN/img_align_celeba/img_align_celeba\"\n",
        "imgs = glob.glob(os.path.join(pth_to_imgs, \"*\"))"
      ],
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-2. Check data type"
      ],
      "metadata": {
        "id": "yLz34AIjzFI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9개의 이미지를 보여줌\n",
        "for i in range(9):\n",
        "   plt.subplot(3, 3, i+1)\n",
        "   img = Image.open(imgs[i])\n",
        "   plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BIwItmZr48ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2. Dataset"
      ],
      "metadata": {
        "id": "dHoQK0Vw5UWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-1. Dataset"
      ],
      "metadata": {
        "id": "TDCud9xuFCx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import torchvision.transforms as tf\n",
        "\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class CelebA(Dataset):\n",
        "   def __init__(self):\n",
        "       self.imgs = glob.glob(\"./GAN/img_align_celeba/img_align_celeba/*.jpg\")\n",
        "\n",
        "       # ❶ 정규화에 이용할 평균과 공분산\n",
        "       mean_std = (0.5, 0.5, 0.5)\n",
        "\n",
        "       # ❷ 입력용 이미지 생성\n",
        "       self.low_res_tf = tf.Compose([\n",
        "           tf.Resize((32, 32)),\n",
        "           tf.ToTensor(),\n",
        "           tf.Normalize(mean_std, mean_std)\n",
        "       ])\n",
        "\n",
        "       # ❸ 정답용 이미지 생성\n",
        "       self.high_res_tf = tf.Compose([\n",
        "           tf.Resize((64, 64)),\n",
        "           tf.ToTensor(),\n",
        "           tf.Normalize(mean_std, mean_std)\n",
        "       ])\n",
        "\n",
        "   def __len__(self):\n",
        "       return len(self.imgs) # ❶ 이미지 갯수 반환\n",
        "\n",
        "   def __getitem__(self, i):\n",
        "       img = Image.open(self.imgs[i])\n",
        "\n",
        "       # ❷ 저화질 이미지는 입력으로\n",
        "       img_low_res = self.low_res_tf(img)\n",
        "       # ❸ 고화질 입력은 정답으로\n",
        "       img_high_res = self.high_res_tf(img)\n",
        "\n",
        "       return [img_low_res, img_high_res]"
      ],
      "metadata": {
        "id": "B4jMESbH5T7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-2. Dataloader"
      ],
      "metadata": {
        "id": "4W4Mk-JGFBRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "dataset = CelebA()\n",
        "\n",
        "batch_size = 8\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "WrUQinHqE2O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3. Module"
      ],
      "metadata": {
        "id": "UPv6ybM8zJYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-1. Generater Basic Blokc"
      ],
      "metadata": {
        "id": "0eqU_bYpGght"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "   def __init__(self, in_channels, out_channels):\n",
        "       super(ResidualBlock, self).__init__()\n",
        "\n",
        "       # 생성자의 구성요소 정의\n",
        "       self.layers = nn.Sequential(\n",
        "           nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "           nn.BatchNorm2d(out_channels),\n",
        "           nn.PReLU(),\n",
        "           nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "           nn.BatchNorm2d(out_channels)\n",
        "       )\n",
        "\n",
        "   def forward(self, x):\n",
        "       x_ = x\n",
        "       x = self.layers(x)\n",
        "\n",
        "       # 합성곱층을 거친 후 원래의 입력 텐서와 더해줌\n",
        "       x = x_ + x\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "5gh77nDhGf1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-2. Generater Upscaling"
      ],
      "metadata": {
        "id": "QQnNmDIS5iyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 업샘플링층의 정의\n",
        "class UpSample(nn.Sequential):\n",
        "   def __init__(self, in_channels, out_channels):\n",
        "       super(UpSample, self).__init__(\n",
        "           nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "           nn.PixelShuffle(upscale_factor=2),\n",
        "           nn.PReLU()\n",
        "       )"
      ],
      "metadata": {
        "id": "G3xpwfLpG2zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-3. Generater"
      ],
      "metadata": {
        "id": "5jAsr6ehHdJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Generator, self).__init__()\n",
        "\n",
        "       # ➊ 첫 번째 합성곱층\n",
        "       self.conv1 = nn.Sequential(\n",
        "           nn.Conv2d(3, 64, kernel_size=9, stride=1, padding=4),\n",
        "           nn.PReLU()\n",
        "       )\n",
        "\n",
        "       # ➋ 합성곱 블록\n",
        "       self.res_blocks = nn.Sequential(\n",
        "           ResidualBlock(in_channels=64, out_channels=64),\n",
        "           ResidualBlock(in_channels=64, out_channels=64),\n",
        "           ResidualBlock(in_channels=64, out_channels=64),\n",
        "       )\n",
        "\n",
        "       self.conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
        "       self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "       # ➌ 업샘플링층\n",
        "       self.upsample_blocks = nn.Sequential(\n",
        "           UpSample(in_channels=64, out_channels=256)\n",
        "       )\n",
        "\n",
        "       # ➍ 마지막 합성곱층\n",
        "       self.conv3 = nn.Conv2d(64, 3, kernel_size=9, stride=1, padding=4)\n",
        "\n",
        "   def forward(self, x):\n",
        "       # ➊ 첫 번째 합성곱층\n",
        "       x = self.conv1(x)\n",
        "       # ➋ 합성곱 블록을 거친 결과와 더하기 위해\n",
        "       # 값을 저장\n",
        "       x_ = x\n",
        "\n",
        "       # ➌ 합성곱 블록\n",
        "       x = self.res_blocks(x)\n",
        "       x = self.conv2(x)\n",
        "       x = self.bn2(x)\n",
        "       # ➍ 합성곱 블록과 첫 번째 합성곱층의 결과를 더함\n",
        "       x = x + x_\n",
        "\n",
        "       # ➎ 업샘플링 블록\n",
        "       x = self.upsample_blocks(x)\n",
        "       # ➏ 마지막 합성곱층\n",
        "       x = self.conv3(x)\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "bShzfwxwHiK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. Discriminater Basic Block"
      ],
      "metadata": {
        "id": "SULUmxD5jVVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 번 거칠 때마다 이미지 크기가 절반이 되는 합성곱층\n",
        "class DiscBlock(nn.Module):\n",
        "   def __init__(self, in_channels, out_channels):\n",
        "       super(DiscBlock, self).__init__()\n",
        "\n",
        "       self.layers = nn.Sequential(\n",
        "           nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n",
        "           nn.BatchNorm2d(out_channels),\n",
        "           nn.LeakyReLU()\n",
        "       )\n",
        "\n",
        "   def forward(self, x):\n",
        "       return self.layers(x)"
      ],
      "metadata": {
        "id": "7i3JhF_RjXlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-5. Discriminater"
      ],
      "metadata": {
        "id": "LANBC3tSjcEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Discriminator, self).__init__()\n",
        "\n",
        "       self.conv1 = nn.Sequential(\n",
        "           nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "           nn.LeakyReLU()\n",
        "       )\n",
        "\n",
        "       self.blocks = DiscBlock(in_channels=64, out_channels=64)\n",
        "\n",
        "       self.fc1 = nn.Linear(65536, 1024)\n",
        "       self.activation = nn.LeakyReLU()\n",
        "       self.fc2 = nn.Linear(1024, 1)\n",
        "       self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "   def forward(self, x):\n",
        "       # ➊ 컨볼루션 층\n",
        "       x = self.conv1(x)\n",
        "       x = self.blocks(x)\n",
        "\n",
        "       # ➋ 1차원으로 펼쳐줌\n",
        "       x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "       # ➌ 이진분류 단계\n",
        "       x = self.fc1(x)\n",
        "       x = self.activation(x)\n",
        "       x = self.fc2(x)\n",
        "       x = self.sigmoid(x)\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "eM7F_8HtjcwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-6. 특징 추출기\n"
      ],
      "metadata": {
        "id": "kppiSY3KkAT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models.vgg import vgg19\n",
        "\n",
        "# VGG19 특징 추출기\n",
        "class FeatureExtractor(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(FeatureExtractor, self).__init__()\n",
        "       # ➊ 사전 학습된 vgg19 모델 정의\n",
        "       vgg19_model = vgg19(pretrained=True)\n",
        "\n",
        "       # ➋ VGG19의 9개 층만을 이용(이미지 사이즈 변경 방지를 위해 폴링 전 층까지만 이용)\n",
        "       self.feature_extractor = nn.Sequential(\n",
        "           *list(vgg19_model.features.children())[:9])\n",
        "\n",
        "   def forward(self, img):\n",
        "       return self.feature_extractor(img)"
      ],
      "metadata": {
        "id": "RypxveWdkBu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4. Learning"
      ],
      "metadata": {
        "id": "Qa9kBj02zz7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-1. Setting"
      ],
      "metadata": {
        "id": "cg8ZCYcJ0JIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ➋ 생성자와 감별자, 특징 추출기 정의\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "feature_extractor = FeatureExtractor().to(device)\n",
        "feature_extractor.eval()\n",
        "\n",
        "# ➌ 생성자와 감별자의 최적화 정의\n",
        "G_optim = Adam(G.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "D_optim = Adam(D.parameters(), lr=0.0001, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "B8clGgz65sxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-2. Check Data and Model Shape"
      ],
      "metadata": {
        "id": "B6Mg0HW6P44V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data shape: {dataset[0][0].shape}, number of data: {len(dataset)}\")\n",
        "print(f\"number of batch: {len(loader)}\")\n",
        "print(D)  #  3*64*64 > 3*64*64 > 64*32*32 > 65536 > 1024 > 1          # (I-K+2*P)/2 + 1\n",
        "print(G)  #  3*32*32 > 64*32*32 > 64*32*32 > 64*64*64 > 3*64*64\n",
        "print(feature_extractor)"
      ],
      "metadata": {
        "id": "uURTEVFlH3lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-3. Learning"
      ],
      "metadata": {
        "id": "lH9EvJSJz-AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "   iterator = tqdm.tqdm(loader)\n",
        "\n",
        "   for i, (low_res, high_res) in enumerate(iterator):\n",
        "       # ❶기울기의 초기화\n",
        "       G_optim.zero_grad()\n",
        "       D_optim.zero_grad()\n",
        "\n",
        "       # ➋ 진짜 이미지와 가짜 이미지의 정답\n",
        "       label_true = torch.ones(batch_size, dtype=torch.float32).to(device)\n",
        "       label_false = torch.zeros(batch_size, dtype=torch.float32).to(device)\n",
        "\n",
        "       # ➌ 생성자 학습\n",
        "       fake_hr = G(low_res.to(device))\n",
        "       GAN_loss = nn.MSELoss()(D(fake_hr), label_true)\n",
        "\n",
        "\n",
        "       ### CNN 특징추출기로부터 추출된 특징의 비교\n",
        "       # ➊ 가짜 이미지의 특징 추출\n",
        "       fake_features = feature_extractor(fake_hr)\n",
        "       # ➋ 진짜 이미지의 특징 추출\n",
        "       real_features = feature_extractor(high_res.to(device))\n",
        "       # ➌ 둘의 차이 비교\n",
        "       content_loss = nn.L1Loss()(fake_features, real_features)\n",
        "\n",
        "\n",
        "       ### 생성자의 손실 정의\n",
        "       loss_G = content_loss + 0.001*GAN_loss\n",
        "       loss_G.backward()\n",
        "       G_optim.step()\n",
        "\n",
        "\n",
        "       ### 감별자 학습\n",
        "       # ➊ 진짜 이미지의 손실\n",
        "       real_loss = nn.MSELoss()(D(high_res.to(device)), label_true)\n",
        "       # ➋ 가짜 이미지의 손실\n",
        "       fake_loss = nn.MSELoss()(D(fake_hr.detach()), label_false)\n",
        "       # ➌ 두 손실의 평균값을 최종 오차로 설정\n",
        "       loss_D = (real_loss + fake_loss) / 2\n",
        "       # ➍ 오차 역전파\n",
        "       loss_D.backward()\n",
        "       D_optim.step()\n",
        "\n",
        "       iterator.set_description(f\"epoch:{epoch} G_loss:{GAN_loss} D_loss:{loss_D}\")\n",
        "\n",
        "torch.save(G.state_dict(), \"SRGAN_G.pth\")\n",
        "torch.save(D.state_dict(), \"SRGAN_D.pth\")"
      ],
      "metadata": {
        "id": "krz6kIYz52wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 5. Evaluation"
      ],
      "metadata": {
        "id": "sdk0NFRA085c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "G.load_state_dict(torch.load(\"SRGAN_G.pth\", map_location=device))\n",
        "\n",
        "with torch.no_grad():\n",
        "   low_res, high_res = dataset[1]\n",
        "\n",
        "   # ➊ 생성자의 입력\n",
        "   input_tensor = torch.unsqueeze(low_res, dim=0).to(device)\n",
        "\n",
        "   # ➋ 생성자가 생성한 고화질 이미지\n",
        "   pred = G(input_tensor)\n",
        "   pred = pred.squeeze()\n",
        "   pred = pred.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "   # ➌ 저화질 이미지의 채널 차원을 가장 마지막으로\n",
        "   low_res = low_res.permute(1, 2, 0).numpy()\n",
        "\n",
        "   # ➍ 저화질 입력과 생성자가 만든 고화질 이미지의 비교\n",
        "   plt.subplot(1, 2, 1)\n",
        "   plt.title(\"low resolution image\")\n",
        "   plt.imshow(low_res)\n",
        "   plt.subplot(1, 2, 2)\n",
        "   plt.imshow(pred)\n",
        "   plt.title(\"predicted high resolution image\")\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "6t5jawBx8ibI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}