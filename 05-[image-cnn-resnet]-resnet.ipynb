{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/01-colab-study_must_have_pytorch/05-%5Bimage-cnn-resnet%5D-resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxkMBWDW9T3P"
      },
      "source": [
        "## STEP 0. Version check and Install Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      },
      "source": [
        "Step 0-1. Version Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvZ7Lm3Apv1B"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNpk3WdHys1f"
      },
      "source": [
        "Step 0-2. Install Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TquybxQaqfE5"
      },
      "source": [
        "## STEP 1. Data Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      },
      "source": [
        "Step 1-1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# ❶ CIFAR10 데이터셋을 불러옴\n",
        "training_data = CIFAR10(\n",
        "    root=\"./\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor())\n",
        "\n",
        "test_data = CIFAR10(\n",
        "    root=\"./\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor())\n",
        "\n",
        "for i in range(9):\n",
        "   plt.subplot(3, 3, i+1)\n",
        "   plt.imshow(training_data.data[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j7LyP731D9K"
      },
      "source": [
        "## STEP 2. Dataset(with Preprocessing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTc2ddgAJgjR"
      },
      "source": [
        "Step 2-1. Preprocessing(cropping, flip, normalize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCEQG7FuJgRm"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "\n",
        "from torchvision.datasets.cifar import CIFAR10\n",
        "from torchvision.transforms import Compose, ToTensor\n",
        "from torchvision.transforms import RandomHorizontalFlip, RandomCrop\n",
        "from torchvision.transforms import Normalize\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "transforms = Compose([\n",
        "   RandomCrop((32, 32), padding=4), #❶ 랜덤 크롭핑\n",
        "   RandomHorizontalFlip(p=0.5), #❷ 랜덤 y축 대칭\n",
        "   ToTensor(),\n",
        "   Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zJNJBOu7SmG"
      },
      "source": [
        "Step 2-2. Setting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BalXjevgTWoy"
      },
      "outputs": [],
      "source": [
        "training_data = CIFAR10(root=\"./\", train=True, download=True, transform=transforms)\n",
        "test_data = CIFAR10(root=\"./\", train=False, download=True, transform=transforms)\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPv6ybM8zJYk"
      },
      "source": [
        "## STEP 3. Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPl-SO7N1cuU"
      },
      "source": [
        "Step 3-1. ResNet BasicBlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SAzde8ETVXi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "   def __init__(self, in_channels, out_channels, kernel_size=3):\n",
        "       super(BasicBlock, self).__init__()\n",
        "\n",
        "       # ❶ 합성곱층 정의\n",
        "       self.c1 = nn.Conv2d(in_channels, out_channels,\n",
        "                           kernel_size=kernel_size, padding=1)\n",
        "       self.c2 = nn.Conv2d(out_channels, out_channels,\n",
        "                           kernel_size=kernel_size, padding=1)\n",
        "       self.downsample = nn.Conv2d(in_channels, out_channels,\n",
        "                                   kernel_size=1)\n",
        "\n",
        "       # ❷ 배치 정규화층 정의\n",
        "       self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "       self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "\n",
        "       self.relu = nn.ReLU()\n",
        "\n",
        "   def forward(self, x):\n",
        "       # ❸스킵 커넥션을 위해 초기 입력을 저장\n",
        "       x_ = x\n",
        "\n",
        "       x = self.c1(x)\n",
        "       x = self.bn1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.c2(x)\n",
        "       x = self.bn2(x)\n",
        "\n",
        "       # ➍합성곱의 결과와 입력의 채널 수를 맞춤\n",
        "       x_ = self.downsample(x_)\n",
        "\n",
        "       # ➎합성곱층의 결과와 저장해놨던 입력값을 더해줌\n",
        "       x += x_\n",
        "       x = self.relu(x)\n",
        "\n",
        "       return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD91Gt4N1k1w"
      },
      "source": [
        "Step 3-2. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlyikZxFTXOZ"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "   def __init__(self, num_classes=10):\n",
        "       super(ResNet, self).__init__()\n",
        "\n",
        "       # ❶ 기본 블록\n",
        "       self.b1 = BasicBlock(in_channels=3, out_channels=64)\n",
        "       self.b2 = BasicBlock(in_channels=64, out_channels=128)\n",
        "       self.b3 = BasicBlock(in_channels=128, out_channels=256)\n",
        "\n",
        "       # ❷ 풀링을 최댓값이 아닌 평균값으로\n",
        "       self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "       # ❸ 분류기\n",
        "       self.fc1 = nn.Linear(in_features=4096, out_features=2048)\n",
        "       self.fc2 = nn.Linear(in_features=2048, out_features=512)\n",
        "       self.fc3 = nn.Linear(in_features=512, out_features=num_classes)\n",
        "\n",
        "       self.relu = nn.ReLU()\n",
        "\n",
        "   def forward(self, x):\n",
        "       # ❶ 기본 블록과 풀링층을 통과\n",
        "       x = self.b1(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.b2(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.b3(x)\n",
        "       x = self.pool(x)\n",
        "\n",
        "       # ❷ 분류기의 입력으로 사용하기 위해 flatten\n",
        "       x = torch.flatten(x, start_dim=1)\n",
        "\n",
        "       # ❸ 분류기로 예측값 출력\n",
        "       x = self.fc1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.fc2(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.fc3(x)\n",
        "\n",
        "       return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa9kBj02zz7m"
      },
      "source": [
        "## STEP 4. Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg8ZCYcJ0JIz"
      },
      "source": [
        "Step 4-1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8clGgz65sxJ"
      },
      "outputs": [],
      "source": [
        "from torch.optim.adam import Adam\n",
        "\n",
        "# 학습을 진행할 프로세서 설정\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# model 생성\n",
        "model = ResNet(num_classes=10)\n",
        "\n",
        "# 모델을 device로 보냄\n",
        "model.to(device)\n",
        "\n",
        "# 학습률 정의\n",
        "lr = 1e-4\n",
        "\n",
        "# 최적화 기법 정의\n",
        "optim = Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH9EvJSJz-AX"
      },
      "source": [
        "Step 4-2. Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krz6kIYz52wm"
      },
      "outputs": [],
      "source": [
        "for epoch in range(30):\n",
        "   iterator = tqdm.tqdm(train_loader)\n",
        "   for data, label in iterator:\n",
        "       # 최적화를 위해 기울기를 초기화\n",
        "       optim.zero_grad()\n",
        "\n",
        "       # 모델의 예측값\n",
        "       preds = model(data.to(device))\n",
        "\n",
        "       # 손실 계산 및 역전파\n",
        "       loss = nn.CrossEntropyLoss()(preds, label.to(device))\n",
        "       loss.backward()\n",
        "       optim.step()\n",
        "\n",
        "       iterator.set_description(f\"epoch:{epoch+1} loss:{loss.item()}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"ResNet.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdk0NFRA085c"
      },
      "source": [
        "## STEP 5. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t5jawBx8ibI"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\"ResNet.pth\", map_location=device))\n",
        "\n",
        "num_corr = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "   for data, label in test_loader:\n",
        "\n",
        "       output = model(data.to(device))\n",
        "       preds = output.data.max(1)[1]\n",
        "       corr = preds.eq(label.to(device).data).sum().item()\n",
        "       num_corr += corr\n",
        "\n",
        "   print(f\"Accuracy:{num_corr/len(test_data)}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
