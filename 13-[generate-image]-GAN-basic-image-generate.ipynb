{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/01-colab-study_must_have_pytorch/13-%5Bgenerate-image%5D-GAN-basic-image-generate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 0. Version check and Install Dependency"
      ],
      "metadata": {
        "id": "LxkMBWDW9T3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0-1. Version Check"
      ],
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ],
      "metadata": {
        "id": "pvZ7Lm3Apv1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0-2. Install Dependency"
      ],
      "metadata": {
        "id": "cNpk3WdHys1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export export KAGGLE_USERNAME=*** && export KAGGLE_KEY=*** && kaggle datasets download -d jessicali9530/celeba-dataset\n",
        "!unzip \"./celeba-dataset.zip\" -d \"./GAN/\""
      ],
      "metadata": {
        "id": "ye2JDNesCfAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1. Check Data"
      ],
      "metadata": {
        "id": "TquybxQaqfE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-1. Load data"
      ],
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# 이미지까지의 경로\n",
        "pth_to_imgs = \"./GAN/img_align_celeba/img_align_celeba\"\n",
        "imgs = glob.glob(os.path.join(pth_to_imgs, \"*\"))"
      ],
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-2. Check data type"
      ],
      "metadata": {
        "id": "yLz34AIjzFI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9개의 이미지를 보여줌\n",
        "for i in range(9):\n",
        "   plt.subplot(3, 3, i+1)\n",
        "   img = Image.open(imgs[i])\n",
        "   plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BIwItmZr48ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2. Dataset"
      ],
      "metadata": {
        "id": "dHoQK0Vw5UWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-1. Dataset"
      ],
      "metadata": {
        "id": "TDCud9xuFCx8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as tf\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# ❶ 이미지의 전처리 과정\n",
        "transforms = tf.Compose([\n",
        "   tf.Resize(64),\n",
        "   tf.CenterCrop(64),\n",
        "   tf.ToTensor(),\n",
        "   tf.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# ❷ ImageFolder()를 이용해 데이터셋을 작성\n",
        "# root는 최상위 경로를, transform은 전처리를 의미합니다.\n",
        "dataset = ImageFolder(\n",
        "   root=\"./GAN/img_align_celeba\",\n",
        "   transform=transforms\n",
        ")"
      ],
      "metadata": {
        "id": "B4jMESbH5T7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-2. Dataloader"
      ],
      "metadata": {
        "id": "4W4Mk-JGFBRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "WrUQinHqE2O-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3. Module"
      ],
      "metadata": {
        "id": "UPv6ybM8zJYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-1. Generater"
      ],
      "metadata": {
        "id": "0eqU_bYpGght"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Generator, self).__init__()\n",
        "\n",
        "       # 생성자를 구성하는 층 정의\n",
        "       self.gen = nn.Sequential(\n",
        "           nn.ConvTranspose2d(100, 512, kernel_size=4, bias=False),\n",
        "           nn.BatchNorm2d(512),\n",
        "           nn.ReLU(),\n",
        "\n",
        "           nn.ConvTranspose2d(512, 256, kernel_size=4,\n",
        "                              stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(256),\n",
        "           nn.ReLU(),\n",
        "\n",
        "           nn.ConvTranspose2d(256, 128, kernel_size=4,\n",
        "                              stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(128),\n",
        "           nn.ReLU(),\n",
        "\n",
        "           nn.ConvTranspose2d(128, 64, kernel_size=4,\n",
        "                              stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(64),\n",
        "           nn.ReLU(),\n",
        "\n",
        "           nn.ConvTranspose2d(64, 3, kernel_size=4,\n",
        "                              stride=2, padding=1, bias=False),\n",
        "           nn.Tanh()\n",
        "       )\n",
        "\n",
        "   def forward(self, x):\n",
        "       return self.gen(x)"
      ],
      "metadata": {
        "id": "5gh77nDhGf1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-2. Discriminator"
      ],
      "metadata": {
        "id": "QQnNmDIS5iyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Discriminator, self).__init__()\n",
        "\n",
        "       # 감별자를 구성하는 층의 정의\n",
        "       self.disc = nn.Sequential(\n",
        "           nn.Conv2d(3, 64, kernel_size=4,\n",
        "                     stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(64),\n",
        "           nn.LeakyReLU(0.2),\n",
        "\n",
        "           nn.Conv2d(64, 128, kernel_size=4,\n",
        "                     stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(128),\n",
        "           nn.LeakyReLU(0.2),\n",
        "\n",
        "           nn.Conv2d(128, 256, kernel_size=4,\n",
        "                     stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(256),\n",
        "           nn.LeakyReLU(0.2),\n",
        "\n",
        "           nn.Conv2d(256, 512, kernel_size=4,\n",
        "                     stride=2, padding=1, bias=False),\n",
        "           nn.BatchNorm2d(512),\n",
        "           nn.LeakyReLU(0.2),\n",
        "\n",
        "           nn.Conv2d(512, 1, kernel_size=4),\n",
        "           nn.Sigmoid()\n",
        "       )\n",
        "\n",
        "   def forward(self, x):\n",
        "       return self.disc(x)"
      ],
      "metadata": {
        "id": "G3xpwfLpG2zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-3. Weight Init"
      ],
      "metadata": {
        "id": "5jAsr6ehHdJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "   # 층의 종류 추출\n",
        "   classname = m.__class__.__name__\n",
        "   if classname.find('Conv') != -1:\n",
        "       # 합성곱층 초기화\n",
        "       nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "   elif classname.find('BatchNorm') != -1:\n",
        "       # 배치정규화층 초기화\n",
        "       nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "       nn.init.constant_(m.bias.data, 0)"
      ],
      "metadata": {
        "id": "bShzfwxwHiK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4. Learning"
      ],
      "metadata": {
        "id": "Qa9kBj02zz7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-1. Setting"
      ],
      "metadata": {
        "id": "cg8ZCYcJ0JIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 생성자 정의\n",
        "G = Generator().to(device)\n",
        "# ❶ 생성자 가중치 초기화\n",
        "G.apply(weights_init)\n",
        "\n",
        "# 감별자 정의\n",
        "D = Discriminator().to(device)\n",
        "# ❷ 감별자 가중치 초기화\n",
        "D.apply(weights_init)\n",
        "\n",
        "G_optim = Adam(G.parameters(), lr=0.0001, betas=(0.5, 0.999))\n",
        "D_optim = Adam(D.parameters(), lr=0.0001, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "B8clGgz65sxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-2. Check Data and Model Shape"
      ],
      "metadata": {
        "id": "B6Mg0HW6P44V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data shape: {dataset[0][0].shape}, number of data: {len(dataset)}\")\n",
        "print(f\"number of batch: {len(loader)}\")\n",
        "print(D)  # 3*64*64 > 64*32*32 > 128*16*16 > 256*8*8 > 512*4*4 > 1*1*1      # (I-K+2*P)/2 + 1\n",
        "print(G)  # 100*1*1 > 512*4*4 > 256*8*8 > 128*16*16 > 64*32*32 > 3*64*64    # K+(W−1)S−2P     # n배 > K=2n, S=n, P=1/2n"
      ],
      "metadata": {
        "id": "uURTEVFlH3lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-3. Learning"
      ],
      "metadata": {
        "id": "lH9EvJSJz-AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for epochs in range(50):\n",
        "for epochs in range(10):\n",
        "   iterator = tqdm.tqdm(enumerate(loader, 0), total=len(loader))\n",
        "\n",
        "   for i, data in iterator:\n",
        "       ### 감별자 진짜 이미지 학습\n",
        "       D_optim.zero_grad()\n",
        "\n",
        "       # ➊ 실제 이미지에는 1, 생성된 이미지는 0으로 정답을 설정\n",
        "       label = torch.ones_like(data[1], dtype=torch.float32).to(device)\n",
        "       label_fake = torch.zeros_like(data[1], dtype=torch.float32).to(device)\n",
        "\n",
        "       # ➋ 실제 이미지를 감별자에 입력\n",
        "       real = D(data[0].to(device))\n",
        "\n",
        "       # ❸ 실제 이미지에 대한 감별자의 오차를 계산\n",
        "       Dloss_real = nn.BCELoss()(torch.squeeze(real), label)\n",
        "       Dloss_real.backward()\n",
        "\n",
        "\n",
        "       ### 감별자 가짜 이미지 학습\n",
        "       # ➊ 가짜 이미지 생성\n",
        "       noise = torch.randn(label.shape[0], 100, 1, 1, device=device)\n",
        "       fake = G(noise)\n",
        "\n",
        "       # 가짜 이미지를 감별자에 입력\n",
        "       output = D(fake.detach())\n",
        "\n",
        "       # 가짜 이미지에 대한 감별자의 오차를 계산\n",
        "       Dloss_fake = nn.BCELoss()(torch.squeeze(output), label_fake)\n",
        "       Dloss_fake.backward()\n",
        "\n",
        "       # ➋ 감별자의 전체 오차를 학습\n",
        "       Dloss = Dloss_real + Dloss_fake\n",
        "       D_optim.step()\n",
        "\n",
        "\n",
        "       ### 생성자 학습\n",
        "       # ➊ 생성자의 학습\n",
        "       G_optim.zero_grad()\n",
        "       output = D(fake)\n",
        "       Gloss = nn.BCELoss()(torch.squeeze(output), label)\n",
        "       Gloss.backward()\n",
        "\n",
        "       G_optim.step()\n",
        "\n",
        "       iterator.set_description(f\"epoch:{epochs} iteration:{i} D_loss:{Dloss} G_loss:{Gloss}\")\n",
        "\n",
        "torch.save(G.state_dict(), \"Generator.pth\")\n",
        "torch.save(D.state_dict(), \"Discriminator.pth\")"
      ],
      "metadata": {
        "id": "krz6kIYz52wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 5. Evaluation"
      ],
      "metadata": {
        "id": "sdk0NFRA085c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "   G.load_state_dict(\n",
        "       torch.load(\"./Generator.pth\", map_location=device))\n",
        "\n",
        "   # 특징 공간 상의 랜덤한 하나의 점을 지정\n",
        "   feature_vector = torch.randn(1, 100, 1, 1).to(device)\n",
        "   # 이미지 생성\n",
        "   pred = G(feature_vector).squeeze()\n",
        "   pred = pred.permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "   plt.imshow(pred)\n",
        "   plt.title(\"predicted image\")\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "6t5jawBx8ibI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}