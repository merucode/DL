{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/01-colab-study_must_have_pytorch/08-%5Bimage-denoise%5D-cea-auto-encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 0. Version check and Install Dependency"
      ],
      "metadata": {
        "id": "LxkMBWDW9T3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0-1. Version Check"
      ],
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ],
      "metadata": {
        "id": "pvZ7Lm3Apv1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0-2. Install Dependency"
      ],
      "metadata": {
        "id": "cNpk3WdHys1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1. Check Data"
      ],
      "metadata": {
        "id": "TquybxQaqfE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-1. Noise Function"
      ],
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "def gaussian_noise(x, scale=0.8):  # ❶ 이미지에 가우스 잡음을 추가하는 함수\n",
        "   gaussian_data_x = x + np.random.normal(\n",
        "       loc=0,\n",
        "       scale=scale,\n",
        "       size=x.shape)  # 가우스 잡음을 더해줌\n",
        "\n",
        "   gaussian_data_x = np.clip(\n",
        "       gaussian_data_x, 0, 1)  # 이미지의 픽셀값을 0과 1 사이로 정규화\n",
        "\n",
        "   gaussian_data_x = torch.tensor(gaussian_data_x) # 파이토치 텐서로 변환\n",
        "   gaussian_data_x = gaussian_data_x.type(torch.FloatTensor)\n",
        "   return gaussian_data_x"
      ],
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-2. Data with Noise"
      ],
      "metadata": {
        "id": "yLz34AIjzFI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터 정의\n",
        "training_data = MNIST(\n",
        "    root=\"./\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor())\n",
        "\n",
        "# 평가 데이터 정의\n",
        "test_data = MNIST(\n",
        "    root=\"./\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor())\n",
        "\n",
        "# 첫 번째 원본 이미지\n",
        "img = training_data.data[0]\n",
        "# 잡음이 섞인 이미지로 변환\n",
        "gaussian = gaussian_noise(img)\n",
        "\n",
        "\n",
        "# 두 이미지 출력\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"original\")\n",
        "plt.imshow(img)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"noisy\")\n",
        "plt.imshow(gaussian)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BIwItmZr48ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2. Dataset"
      ],
      "metadata": {
        "id": "dHoQK0Vw5UWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-1. Dataset"
      ],
      "metadata": {
        "id": "-cBZwqY2nBYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "class Denoising(Dataset):\n",
        "   def __init__(self):\n",
        "       # 원본 이미지를 담고있는 MNIST 데이터\n",
        "       self.mnist = MNIST(\n",
        "           root=\"./\",\n",
        "           train=True,\n",
        "           download=True,\n",
        "           transform=ToTensor())\n",
        "       self.data = []  # 잡음이 낀 데이터를 담는 리스트\n",
        "\n",
        "        # ❶ 잡음 입히기\n",
        "       for i in range(len(self.mnist)):\n",
        "           noisy_input = gaussian_noise(self.mnist.data[i])\n",
        "           input_tensor = torch.tensor(noisy_input)\n",
        "           self.data.append(torch.unsqueeze(input_tensor, dim=0))\n",
        "\n",
        "   def __len__(self):\n",
        "       return len(self.data)\n",
        "\n",
        "   def __getitem__(self, i):\n",
        "       data = self.data[i]\n",
        "\n",
        "       # 원본 이미지도 0과 1 사이로 값을 맞춰줌\n",
        "       label = self.mnist.data[i]/255\n",
        "\n",
        "       return data, label"
      ],
      "metadata": {
        "id": "B4jMESbH5T7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-2. DataLoader"
      ],
      "metadata": {
        "id": "2Sdsg_xbnFpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "trainset = Denoising()  # 학습에 이용할 데이터셋\n",
        "train_loader = DataLoader(trainset, batch_size=32)  # 한 번에 이미지 32장 사용"
      ],
      "metadata": {
        "id": "uvpoQ-XCm_4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3. Module"
      ],
      "metadata": {
        "id": "UPv6ybM8zJYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-1. Basic Block"
      ],
      "metadata": {
        "id": "LLTDkAf-ln5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BasicBlock(nn.Module):  # 4장에서 사용한 CNN 블록을 이용\n",
        "   def __init__(self, in_channels, out_channels, hidden_dim):\n",
        "       super(BasicBlock, self).__init__()\n",
        "\n",
        "       self.conv1 = nn.Conv2d(\n",
        "           in_channels,\n",
        "           hidden_dim,\n",
        "           kernel_size=3,\n",
        "           padding=1)\n",
        "       self.conv2 = nn.Conv2d(\n",
        "           hidden_dim,\n",
        "           out_channels,\n",
        "           kernel_size=3,\n",
        "           padding=1)\n",
        "       self.relu = nn.ReLU()\n",
        "\n",
        "   def forward(self, x):\n",
        "       x = self.conv1(x)\n",
        "       x = self.relu(x)\n",
        "       x = self.conv2(x)\n",
        "       x = self.relu(x)\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "QQnNmDIS5iyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-2. Encoder Model"
      ],
      "metadata": {
        "id": "5HpMwRwwlo9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Encoder, self).__init__()\n",
        "\n",
        "       # ❶ 입력 채널이 1인 것에 주의\n",
        "       self.conv1 = BasicBlock(in_channels=1, out_channels=16, hidden_dim=16)\n",
        "       self.conv2 = BasicBlock(in_channels=16, out_channels=8, hidden_dim=8)\n",
        "\n",
        "       self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "   def forward(self, x):  # CNN과 동일하게 합성곱층을 거치고 풀링을 해줌\n",
        "       x = self.conv1(x)\n",
        "       x = self.pool(x)\n",
        "       x = self.conv2(x)\n",
        "       x = self.pool(x)\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "83c0AJcAlnp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-3. Decoder Model"
      ],
      "metadata": {
        "id": "1s3DAiWGmBqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Decoder, self).__init__()\n",
        "       self.conv1 = BasicBlock(in_channels=8, out_channels=8, hidden_dim=8)\n",
        "       self.conv2 = BasicBlock(in_channels=8, out_channels=16, hidden_dim=16)\n",
        "\n",
        "       # ❶출력층은 BasicBlock이 아닌 합성곱층\n",
        "       self.conv3 = nn.Conv2d(in_channels=16, out_channels=1,\n",
        "                              kernel_size=3, padding=1)\n",
        "\n",
        "       # 업샘플링층\n",
        "       self.upsample1 = nn.ConvTranspose2d(8, 8, kernel_size=2, stride=2)\n",
        "       self.upsample2 = nn.ConvTranspose2d(16, 16, kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "   # 인코더의 풀링 대신 입력 크기를 키우는 업샘플링 이용\n",
        "   def forward(self, x):\n",
        "       x = self.conv1(x)\n",
        "       x = self.upsample1(x)\n",
        "       x = self.conv2(x)\n",
        "       x = self.upsample2(x)\n",
        "       x = self.conv3(x)\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "8CYWI4hdmB4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. Model"
      ],
      "metadata": {
        "id": "IBljh4iImE4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CAE(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(CAE, self).__init__()\n",
        "\n",
        "       self.enc = Encoder()  # 인코더 층의 정의\n",
        "       self.dec = Decoder()  # 디코더 층의 정의\n",
        "\n",
        "   def forward(self, x):  # 인코더, 디코더를 거친 후, 채널 차원을 삭제\n",
        "       x = self.enc(x)    # 인코더로 특징 추출\n",
        "       x = self.dec(x)    # 디코더로 이미지 복원\n",
        "       x = torch.squeeze(x) # 채널 차원의 삭제\n",
        "\n",
        "       return x"
      ],
      "metadata": {
        "id": "hLyF3KSwmCDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4. Learning"
      ],
      "metadata": {
        "id": "Qa9kBj02zz7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-1. Setting"
      ],
      "metadata": {
        "id": "cg8ZCYcJ0JIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CAE().to(device)  # 디노이징에 사용할 오토인코더 모델\n",
        "\n",
        "lr = 0.001\n",
        "\n",
        "optim = Adam(params=model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "B8clGgz65sxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-2. Learning"
      ],
      "metadata": {
        "id": "lH9EvJSJz-AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(20):\n",
        "   iterator = tqdm.tqdm(train_loader)\n",
        "\n",
        "   for data, label in iterator:\n",
        "       optim.zero_grad()\n",
        "       pred = model(data.to(device))\n",
        "\n",
        "       loss = nn.MSELoss()(torch.squeeze(pred), label.to(device))  # 손실의 계산\n",
        "       loss.backward()  # 오차 역전파\n",
        "       optim.step()  # 최적화\n",
        "       iterator.set_description(f\"epoch{epoch+1} loss:{loss.item()}\")\n",
        "\n",
        "torch.save(model.state_dict(), \"./CAE.pth\")  # 모델의 가중치 저장"
      ],
      "metadata": {
        "id": "krz6kIYz52wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 5. Evaluation"
      ],
      "metadata": {
        "id": "sdk0NFRA085c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.cpu()  # ❶ 모델의 출력값을 cpu로 이동\n",
        "\n",
        "with torch.no_grad():\n",
        "   # 학습이 완료된 가중치를 불러오기\n",
        "   model.load_state_dict(torch.load(\"./CAE.pth\", map_location=device))\n",
        "\n",
        "   img = test_data.data[0]         # 시각화에 사용할 이미지 한 장을 불러오기\n",
        "   gaussian = gaussian_noise(img)  # 이미지에 가우스 잡음을 입히기\n",
        "   input = torch.unsqueeze(gaussian, dim=0) # 모델의 입력 모양에 맞춰 채널 차원 추가\n",
        "   input.type(torch.FloatTensor)  # ❷ 가중치와 입력의 데이터형을 맞춤\n",
        "   input.to(device)\n",
        "   input = torch.unsqueeze(input, dim=0)  # 배치 크기1을 위한 배치 차원을 추가\n",
        "\n",
        "   plt.subplot(1, 3, 1)\n",
        "   plt.imshow(torch.squeeze(gaussian))\n",
        "   plt.subplot(1, 3, 2)\n",
        "   plt.imshow(torch.squeeze(model(input)))\n",
        "   plt.subplot(1, 3, 3)\n",
        "   plt.imshow(torch.squeeze(img))\n",
        "   plt.show()"
      ],
      "metadata": {
        "id": "6t5jawBx8ibI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7U_k7-xobB3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}