{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/92-Colab-Kaggle-ML-Classification/11-01_%5B%5D_Detect-sleep-states(basic).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZmla44eMnQC"
      },
      "source": [
        "# Imformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_8PiW9AMqQh"
      },
      "source": [
        "* Title : [Detect Sleep States](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/data)\n",
        "* Type : Multiclass Classification\n",
        "* Evaluation : -\n",
        "* Model : -\n",
        "* Python version: 3.10.12\n",
        "* Basic library version\n",
        "  * sklearn(scikit-learn==1.2.2)\n",
        "  * numpy(numpy==1.23.5)\n",
        "  * pandas(pandas==1.5.3)\n",
        "  * matplotlib(matplotlib==3.7.1)\n",
        "  * seaborn(seaborn==0.12.2)\n",
        "* Addtional Library version\n",
        "* Considering Library version\n",
        "* Improvement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxkMBWDW9T3P"
      },
      "source": [
        "# STEP 0. Version check and Install Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfgM8S72TidO"
      },
      "source": [
        "Step 0-1. Install Dependency"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "collapsed": true,
        "id": "l28uc4WKx7tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      },
      "source": [
        "Step 0-2. Version Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pvZ7Lm3Apv1B"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9v0TRhv5TudL"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOF78xJ1T2lL"
      },
      "source": [
        "Step 0-3. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9m2Gh7jjT5QL"
      },
      "outputs": [],
      "source": [
        "!export KAGGLE_USERNAME=*** && export KAGGLE_KEY=*** && kaggle competitions download -c child-mind-institute-detect-sleep-states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O8C7SzT7UlEu"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "with ZipFile(data_path + 'child-mind-institute-detect-sleep-states.zip') as zipper:\n",
        "  zipper.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TquybxQaqfE5"
      },
      "source": [
        "# STEP 1. Check Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data 정보 및 분석 결과"
      ],
      "metadata": {
        "id": "UvzP2ycCu6EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* train_series.parquet\n",
        "  * series_id- 각 가속도계 시리즈의 고유 식별자입니다.\n",
        "  * step- 계열 내의 각 관측값에 대한 정수 시간 간격입니다.\n",
        "  * timestamp- ISO 8601 형식의 해당 날짜/시간 %Y-%m-%dT%H:%M:%S%z.\n",
        "  * anglez- GGIR 패키지 에서 계산 및 설명된 바와 같이 , z 각도는 수면 감지에 일반적으로 사용되는 개별 가속도계 구성 요소에서 파생된 측정 기준으로, 신체의 수직 축에 대한 팔의 각도를 나타냅니다.\n",
        "  * enmo- GGIR 패키지 에 의해 계산되고 설명된 대로 ENMO는 모든 가속도계 신호 중 유클리드 표준 마이너스 하나이며 음수 값은 0으로 반올림됩니다. 이 공간에는 가속도에 대한 표준 측정값이 없지만 이는 일반적으로 계산되는 여러 기능 중 하나입니다.\n",
        "* test_series.parquet - 위와 동일한 필드를 포함하는 테스트 데이터\n",
        "* train_events.csv - 시작 및 깨우기 이벤트를 기록하는 훈련 세트의 시리즈에 대한 수면 로그입니다.\n",
        "  * series_id- `train_series.parquet`  각 가속도계 데이터 계열에 대한 고유 식별자입니다.\n",
        "  * nightonset- `onset / wakeup` 사건 쌍 의 열거 . 매일 밤 최대 한 쌍의 이벤트가 발생할 수 있습니다.\n",
        "  * event- 이벤트 유형(`onset or wakeup`)입니다.\n",
        "  * step- timestamp가속도계 시리즈에 기록된 이벤트 발생 시간"
      ],
      "metadata": {
        "id": "FVHWi6Fhu_Xk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code"
      ],
      "metadata": {
        "id": "dZwt-joQvAcz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      },
      "source": [
        "Step 1-1. Check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "data_path = '/content/'\n",
        "\n",
        "train_events = pd.read_csv(data_path + 'train_events.csv')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_events.shape, submission.shape"
      ],
      "metadata": {
        "id": "JmFEi8QFxIVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_events"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qlcKhOrayMWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.head(2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Tmm54wizyYkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_events.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mAJQjbwW0gCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_events.groupby('series_id').head(1)[\"event\"].unique())  # Check that all of the series start off in the awake state (i.e. the very first event is the onset of sleep):\n",
        "\n",
        "print(train_events.groupby('series_id').tail(1)[\"event\"].unique())  # Check that all of the series end in the awake state (i.e. the very last event is a wakeup):\n",
        "\n",
        "series_has_NaN = train_events.groupby('series_id')['step'].apply(lambda x: x.isnull().any())  # How many series have NaN values?\n",
        "print(series_has_NaN.value_counts())\n",
        "\n",
        "no_NaN_series = series_has_NaN[~series_has_NaN].index.tolist()  # We see the following 37 series have no NaN values whatsoever:\n",
        "\n",
        "# also drop these two \"truncated\" events series seen in EDA:\n",
        "no_NaN_series.remove('31011ade7c0a') # incomplete events data\n",
        "no_NaN_series.remove('a596ad0b82aa') # incomplete events data\n",
        "\n",
        "no_NaN_series"
      ],
      "metadata": {
        "id": "Srfhx5msyYWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_series(series):\n",
        "    train_series = pd.read_parquet(data_path + \"train_series.parquet\", filters=[('series_id','=',series)])\n",
        "    train_events = pd.read_csv(data_path + \"train_events.csv\").query('series_id == @series')\n",
        "\n",
        "    train_events = train_events.dropna()\n",
        "    train_events[\"step\"]  = train_events[\"step\"].astype(\"int\")\n",
        "    train_events[\"awake\"] = train_events[\"event\"].replace({\"onset\":1,\"wakeup\":0})\n",
        "\n",
        "    train = pd.merge(train_series, train_events[['step','awake']], on='step', how='left')\n",
        "    train[\"awake\"] = train[\"awake\"].bfill(axis ='rows')\n",
        "    # final section:\n",
        "    # train_events.groupby('series_id').tail(1)[\"event\"].unique()\n",
        "    # Result: the last event is always a \"wakeup\"\n",
        "    train['awake'] = train['awake'].fillna(1) # awake\n",
        "    train[\"awake\"] = train[\"awake\"].astype(\"int\")\n",
        "    return(train)"
      ],
      "metadata": {
        "id": "EmY5dt4bzvui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "smaller_train_data = []\n",
        "\n",
        "for series_id in no_NaN_series:\n",
        "    train = get_train_series(series_id)\n",
        "    smaller_train_data.append(train)\n",
        "\n",
        "    # vizualize these series\n",
        "    #display(Markdown('###  anglez for series ' + series_id))\n",
        "    fig, ax = plt.subplots(figsize=(20, 3))\n",
        "    sns.lineplot(data=train, x=\"step\", y=\"anglez\",hue=\"awake\", linewidth = 0.5)\n",
        "    plt.show();\n",
        "    #display(Markdown('###  enmo for series ' + series_id))\n",
        "    fig, ax = plt.subplots(figsize=(20, 3))\n",
        "    sns.lineplot(data=train, x=\"step\", y=\"enmo\",hue=\"awake\", linewidth = 0.5)\n",
        "    plt.show();\n",
        "    del train\n",
        "    gc.collect();"
      ],
      "metadata": {
        "id": "6JrnKhYPzxOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*** https://www.kaggle.com/code/carlmcbrideellis/zzzs-make-small-starter-datasets-target\n"
      ],
      "metadata": {
        "id": "gg1ZT1t-zxVu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rtKbcPQzxdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nkDapajCzxlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vc-L4s3pyY2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 결측값(-1) 확인\n",
        "import numpy as np\n",
        "import missingno as msno\n",
        "\n",
        "# 훈련 데이터 복사본에서 -1을 np.NaN로 변환\n",
        "train_copy = train.copy().replace(-1, np.NaN)\n",
        "\n",
        "# 결측값 시각화(처음 28개만)\n",
        "msno.bar(df=train_copy.iloc[:, 1:28], figsize=(13, 6))  # ★ ps_reg_03, ps_car_03_cat, ps_car_05_cat 결측값 많음"
      ],
      "metadata": {
        "id": "bYf0KRCm0W7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나머지 결측값 시각화\n",
        "msno.bar(df=train_copy.iloc[:, 28:], figsize=(13, 6)) # ★ ps_car_14 결측값 존재"
      ],
      "metadata": {
        "id": "2qXlcdHv1GFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값 메트릭스\n",
        "msno.matrix(df=train_copy.iloc[:, 1:28], figsize=(13, 6))"
      ],
      "metadata": {
        "id": "xsIkQeSq1lbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 피쳐 요약표\n",
        "def resumetable(df):\n",
        "  print(f\"데이터셋 형상: {df.shape}\")\n",
        "  summary = pd.DataFrame(df.dtypes, columns=['데이터 타입'])\n",
        "  #summary = summary.reset_index()\n",
        "  #summary = summary.rename(columns={'index': '피쳐'})\n",
        "  summary['결측값 갯수'] = (df == -1).sum().values # 피처별 -1 개수(이번 데이터 특성)\n",
        "  summary['고유값 개수'] = df.nunique().values\n",
        "  summary['데이터 종류'] = None\n",
        "  for col in df.columns:\n",
        "    if 'bin' in col or col =='target':\n",
        "      summary.loc[col, '데이터 종류'] = '이진형'\n",
        "    elif 'cat' in col:\n",
        "      summary.loc[col, '데이터 종류'] = '명목형'\n",
        "    elif df[col].dtype == float:\n",
        "      summary.loc[col, '데이터 종류'] = '연속형'\n",
        "    elif df[col].dtype ==int:\n",
        "      summary.loc[col, '데이터 종류'] = '순서형'\n",
        "\n",
        "  return summary\n",
        "\n",
        "summary = resumetable(train)\n",
        "summary"
      ],
      "metadata": {
        "id": "PNKD20DFZoXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 데이터 요약표를 통한 칼럼 호출\n",
        "summary[summary['데이터 타입'] == 'float64'].index"
      ],
      "metadata": {
        "id": "t66XcFpL22bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-2. Features Info"
      ],
      "metadata": {
        "id": "myJ6kCpc0CAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "★ 분석결과\n",
        "* ps_reg_03, ps_car_03_cat, ps_car_05_cat, ps_car_14 결측값 많음"
      ],
      "metadata": {
        "id": "d7jFrfiLaePH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-3. Feature Engineering"
      ],
      "metadata": {
        "id": "gs0__czf1NiH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLz34AIjzFI_"
      },
      "source": [
        "# STEP 2. Data Visualize\n",
        "★ 분석결과\n",
        "* 타깃 피쳐\n",
        "  * 타깃값의 비율차이가 큼 → 작은 타깃값 잘 예측하는 게 중요 → 고윳값 별 타깃값 비율 확인 필요\n",
        "  * 고윳값 마다 타깃값 비율이 다르고, 신뢰구간이 좁아야 유효한 피쳐\n",
        "* 이진 피쳐\n",
        "  * ps_ind_10_bin ~ ps_ind_13_bin : 신뢰구간이 넓어서 통계적 유효성이 떨어짐 → 제거\n",
        "  * ps_calc_15_bin ~ ps_calc_20_bin : 고윳값 0, 1에 대한 타깃값 차이가 없음 → 타깃값 예측력이 없으므로 제거\n",
        "* 명목 피쳐\n",
        "  * 결측값에 대한 타깃값 비율도 신뢰구간이 넓다는 점을 감안해도 다른 값과 차이 존재 → 결측값 예측력 존재 하므로 모두 이용\n",
        "* 순서 피쳐\n",
        "  * ps_ind_14 : 타깃값 비율의 신뢰구간이 넓어 통계적 유효성이 떨어짐 → 삭제\n",
        "  * ps_calc_04 ~ ps_cal_14 : 타깃값 비율 차이 없거나 신뢰구간 넓음 → 삭제\n",
        "* 연속 피쳐\n",
        "  * ps_calc_01 ~ ps_calc_03 : 타깃값 비율 차이 없음 → 제거\n",
        "  * (상관관계) ps_car_12, ps_car_14 강한 상관관계 : ps_car_14 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2-1. Count Plot"
      ],
      "metadata": {
        "id": "pq5d4NNkANEH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A5ybi6s9V5-6"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WRhv3MIpDmyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 네모 도형 객체를 순회화며 막대 상단에 타깃값 비율 표시\n",
        "def write_percent(ax, total_size):\n",
        "  for patch in ax.patches:\n",
        "    height = patch.get_height() # 도형 높이(데이터 개수)\n",
        "    width = patch.get_width()   # 도형 너비\n",
        "    left_coord = patch.get_x()  # 도형 왼쪽 테두리의 x축 위치\n",
        "    percent = height/total_size*100\n",
        "\n",
        "    # x,y 좌표에 텍스트 입력\n",
        "    ax.text(x=left_coord + width/2.0,\n",
        "            y=height + total_size*0.001,\n",
        "            s=f'{percent:1.1f}%',\n",
        "            ha='center')"
      ],
      "metadata": {
        "id": "oWWPuSMH3UnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Count Plot : 범주형 데이터 갯수 확인\n",
        "mpl.rc('font', size=15) # 폰트 크기를 15로 설정\n",
        "plt.figure(figsize=(3, 3))\n",
        "\n",
        "# 타깃값 분포 카운트플롯\n",
        "ax = sns.countplot(x='target', data=train)\n",
        "write_percent(ax, len(train)) # 비율 표시\n",
        "ax.set_title('Target Distributuion')\n",
        "# ★ 타깃값의 비율차이가 큼 → 작은 타깃값 잘 예측하는 게 중요 → 고윳값 별 타깃값 비율 확인 필요\n",
        "# ★ 고윳값 마다 타깃값 비율이 다르고, 신뢰구간이 좁아야 유효한 피쳐"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8kVoRsDG5Mmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2-2. Binary Feature"
      ],
      "metadata": {
        "id": "0Ls0erA9APtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "### 이진 피처 Bar Plot에 타깃 비율 같이 그리기\n",
        "def plot_target_ratio_by_features(df, features, num_rows, num_cols, size=(12,18)):\n",
        "  mpl.rc('font', size=9)\n",
        "  plt.figure(figsize=size)\n",
        "  grid = gridspec.GridSpec(num_rows, num_cols)  # 서브플롯 배치\n",
        "  plt.subplots_adjust(wspace=0.3, hspace=0.3)  # 서브플롯 여백\n",
        "\n",
        "  for idx, feature in enumerate(features):\n",
        "    ax = plt.subplot(grid[idx])\n",
        "    # ax축에 고윳값별 타깃값 1 비율 막대 그래프 그리기\n",
        "    sns.barplot(x=feature, y='target', data=df, palette='Set2', ax=ax)"
      ],
      "metadata": {
        "id": "Le7gsW2W4kA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bin_features = summary[summary['데이터 종류']=='이진형'].index # 이진 피처\n",
        "plot_target_ratio_by_features(train, bin_features, num_rows=6, num_cols=3)\n",
        "\n",
        "# ★ ps_ind_10_bin ~ ps_ind_13_bin : 신뢰구간이 넓어서 통계적 유효성이 떨어짐 → 제거\n",
        "# ★ ps_calc_15_bin ~ ps_calc_20_bin : 고윳값 0, 1에 대한 타깃값 차이가 없음 → 타깃값 예측력이 없으므로 제거"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qcEOTSgr4kMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-3 Nominal Feature"
      ],
      "metadata": {
        "id": "cM8nvZ1J4kXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nom_features = summary[summary['데이터 종류']=='명목형'].index\n",
        "plot_target_ratio_by_features(train, nom_features, num_rows=7, num_cols=2)\n",
        "\n",
        "# ★ ps_ind_02_cat : 결측값에 대한 타깃값 비율 많음 → 결측값 자체가 타깃값에 대한 예측력 존재\n",
        "# ★ ps_car_02_cat : 결측값에 대한 타깃값 비율 0 → 결측값 자체가 타깃값에 대한 예측력 존재\n",
        "# ★ 그 외 결측값에 대한 타깃값 비율도 신뢰구간이 넓다는 점을 감안해도 다른 값과 차이 존재 → 결측값 예측력 존재 하므로 모두 이용"
      ],
      "metadata": {
        "id": "i4p_78CU5M9S",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-4. Orderial Feature"
      ],
      "metadata": {
        "id": "s9Fh5FwwDo2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ord_features = summary[summary['데이터 종류']=='순서형'].index\n",
        "plot_target_ratio_by_features(train, ord_features, num_rows=8, num_cols=2)\n",
        "\n",
        "# ★ ps_ind_14 : 타깃값 비율의 신뢰구간이 넓어 통계적 유효성이 떨어짐 → 삭제\n",
        "# ★ ps_calc_04 ~ ps_cal_14 : 타깃값 비율 차이 없거나 신뢰구간 넓음 → 삭제"
      ],
      "metadata": {
        "id": "58Rmad_cD0Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-5. Continuous Feature"
      ],
      "metadata": {
        "id": "cLTPPbe2Gr9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cut 함수로 연속 구간을 나눈뒤 출력\n",
        "cont_features = summary[summary['데이터 종류']=='연속형'].index\n",
        "\n",
        "plt.figure(figsize=(12, 16))\n",
        "grid = gridspec.GridSpec(5, 2)  # 서브플롯 배치\n",
        "plt.subplots_adjust(wspace=0.3, hspace=0.3)  # 서브플롯 여백\n",
        "\n",
        "for idx, cont_feature in enumerate(cont_features):\n",
        "  # 값을 5개 구간으로 나누기\n",
        "  train[cont_feature] = pd.cut(train[cont_feature], 5)\n",
        "\n",
        "  ax = plt.subplot(grid[idx])\n",
        "  sns.barplot(x=cont_feature, y='target', data=train, palette='Set2', ax=ax)\n",
        "  ax.tick_params(axis='x', labelrotation=10)\n",
        "\n",
        "# ★ ps_calc_01 ~ ps_calc_03 : 타깃값 비율 차이 없음 → 제거"
      ],
      "metadata": {
        "id": "rzHr5PS5G0al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-6. Continuous Feature(Correlation)"
      ],
      "metadata": {
        "id": "8PpcuRdtATyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# np.NaN 값 삭제\n",
        "train_copy = train_copy.dropna()"
      ],
      "metadata": {
        "id": "b_mgRmxWIPxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "cont_corr = train_copy[cont_features].corr()    # 연속형 피쳐 상관관계\n",
        "sns.heatmap(cont_corr, annot=True, cmap='OrRd') # 히트맵 그리기\n",
        "\n",
        "# ★ ps_car_12, ps_car_14 강한 상관관계 : ps_car_14 제거 후 성능 상승\n",
        "# ★ ps_reg_02, ps_reg_03 강한 상관관계 : ps_reg_03 삭제 후 성능 저하로 유지"
      ],
      "metadata": {
        "id": "dXBehwMPIP8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwqEIVGS1rtU"
      },
      "source": [
        "# STEP 3. Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-1. Load Data"
      ],
      "metadata": {
        "id": "l_HvIT43CKgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "data_path = '/content/'\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터 경로 설정\n",
        "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
        "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
      ],
      "metadata": {
        "id": "6HpCCR99CKrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-2. Concat Data(Apply same feature engineering with train, test)"
      ],
      "metadata": {
        "id": "MJrEFkRoCTkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([train, test], ignore_index=True) # 훈련 데이터와 테스트 데이터 합치기\n",
        "all_data = all_data.drop('target', axis=1)  # 타깃값 제거\n",
        "all_data.tail(3)"
      ],
      "metadata": {
        "id": "QiB_GwbkCT1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = all_data.columns # 전체 피처\n",
        "all_features"
      ],
      "metadata": {
        "id": "jDnKMZbdJXcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-3. Norminal: One-Hot Encoding"
      ],
      "metadata": {
        "id": "IujIhpsmCUAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 명목형 피처 추출\n",
        "cat_features = [feature for feature in all_features if 'cat'in feature]\n",
        "\n",
        "onehot_encoder = OneHotEncoder()   # 원핫인코더 생성\n",
        "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])\n",
        "\n",
        "encoded_cat_matrix"
      ],
      "metadata": {
        "id": "vRNZVzkcnAVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. Remove Feature"
      ],
      "metadata": {
        "id": "0o-Eo49JJ3W7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 불필요한 피처\n",
        "drop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n",
        "\n",
        "# 1) 명목형 피쳐, 2) calc 분류의 피처, 3) 추가 제거할 피처를 제외한 피처\n",
        "remaining_features = [feature for feature in all_features\n",
        "                      if ('cat' not in feature and\n",
        "                          'calc' not in feature and\n",
        "                          feature not in drop_features)]"
      ],
      "metadata": {
        "id": "gjlYI-xMJ5qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-5. Merge Feature"
      ],
      "metadata": {
        "id": "TyJNYT5sKzTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data[remaining_features]),\n",
        "                               encoded_cat_matrix],\n",
        "                              format='csr')"
      ],
      "metadata": {
        "id": "WwBQwjofK2b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-6. Divide Data(train, test, valid)"
      ],
      "metadata": {
        "id": "2jOT_t9EE6X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = len(train)  # 훈련 데이터 개수\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 나누기\n",
        "X = all_data_sprs[:num_train]\n",
        "X_test = all_data_sprs[num_train:]\n",
        "\n",
        "y = train['target'].values"
      ],
      "metadata": {
        "id": "81ISFus2E6jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4. Evaluation Function"
      ],
      "metadata": {
        "id": "jBC8EeFJLrco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 정규화된 지니계수\n",
        "import numpy as np\n",
        "\n",
        "def eval_gini(y_true, y_pred):\n",
        "  # 실제값과 예측값의 크기가 같은지 서로 확인(다르면 오류)\n",
        "  assert y_true.shape == y_pred.shape\n",
        "\n",
        "  n_samples = y_true.shape[0]                       # 데이터 개수\n",
        "  L_mid = np.linspace(1 / n_samples, 1, n_samples)  # 대각선 값\n",
        "\n",
        "  # 1) 예측값에 대한 지니계수\n",
        "  pred_order = y_true[y_pred.argsort()] # y_pred 크기 순으로 y_true 값 정렬\n",
        "  L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n",
        "  G_pred = np.sum(L_mid - L_pred) # 예측값에 대한 지니 계수\n",
        "\n",
        "  # 2) 예측이 완벽할 때 지니계수\n",
        "  true_order = y_true[y_true.argsort()] # y_true 크기 순으로 y_true 값 정렬\n",
        "  L_true = np.cumsum(true_order) / np.sum(true_order)  # 로렌츠 곡선\n",
        "  G_true = np.sum(L_mid - L_true) # 예측값이 완벽할 때 지니계수\n",
        "\n",
        "  # 정규화된 지니계수\n",
        "  return G_pred / G_true"
      ],
      "metadata": {
        "id": "vWAj3a-yLuFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM용 gini() 함수\n",
        "def gini(preds, dtrain):\n",
        "  labels = dtrain.get_label()\n",
        "  return 'gini', eval_gini(labels, preds), True   # 평가지표 이름, 평가점수, 평가 점수가 높을수록 좋은지 여부"
      ],
      "metadata": {
        "id": "8Vhb7-k5MxDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4. Model\n"
      ],
      "metadata": {
        "id": "BDwpbveiFn07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "rmWF-7pEFn_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5. Learning"
      ],
      "metadata": {
        "id": "XPEeIrtQGJIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5-1. Setting"
      ],
      "metadata": {
        "id": "5gB6dvLlGJS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# K 폴드 교차 검증기\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n",
        "\n",
        "# LightGBM 하이퍼파라미터 설정\n",
        "params = {'objective':'binary',\n",
        "          'learning_rate':0.01,\n",
        "          'force_row_wise':True,  # 경고 문구 제거\n",
        "          'random_state':0}\n",
        "\n",
        "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
        "oof_val_preds = np.zeros(X.shape[0])\n",
        "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
        "oof_test_preds = np.zeros(X_test.shape[0])"
      ],
      "metadata": {
        "id": "iaOEqUK4GJaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5-2. Learning(OOF)"
      ],
      "metadata": {
        "id": "uMmENV_FGPBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OOF 방식으로 모델 훈련, 검증, 예측\n",
        "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "  # 각 폴드를 구분하는 문구 출력\n",
        "  print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
        "\n",
        "  # 훈련용 데이터, 검증용 데이터 설정\n",
        "  X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n",
        "  X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n",
        "\n",
        "  # LightGBM 전용 데이터셋 생성\n",
        "  dtrain = lgb.Dataset(X_train, y_train)\n",
        "  dvalid = lgb.Dataset(X_valid, y_valid)\n",
        "\n",
        "  # LightGBM 모델 훈련\n",
        "  lgb_model = lgb.train(params=params,          # 훈련용 하이퍼파라미터\n",
        "                        train_set=dtrain,       # 훈련 데이터셋\n",
        "                        num_boost_round=1000,   # 부스팅 반복 횟수\n",
        "                        valid_sets=dvalid,      # 검증 데이터셋\n",
        "                        feval=gini,             # 평가지표\n",
        "                        early_stopping_rounds=100,  # 조기종료 조건\n",
        "                        verbose_eval=100)       # 100번째마다 점수 출력\n",
        "\n",
        "  # 테스트 데이터를 활용해 OOF 예측\n",
        "  oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n",
        "  # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n",
        "  oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
        "\n",
        "  # 검증 데이터 예측 확률에 대한 정규화 지니계수\n",
        "  gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n",
        "  print(f\"폴드 {idx+1} 지니계수: {gini_score}\\n\")"
      ],
      "metadata": {
        "id": "2Z71NNIGGPKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TzxvoFCAZT7"
      },
      "source": [
        "# STEP 6. Prediction and Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6-1. Prediction"
      ],
      "metadata": {
        "id": "Iwjg_6nsH2gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('OOF 검증 데이터 지니계수: ', eval_gini(y, oof_val_preds))"
      ],
      "metadata": {
        "id": "0Cs_Px6aH8h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrKX3dBvF5Ib"
      },
      "source": [
        "Step 6-2. Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7NJo_4fF6U-"
      },
      "outputs": [],
      "source": [
        "submission['target'] = oof_test_preds\n",
        "submission.to_csv('submission.csv')   # 제출 파일 생성"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}