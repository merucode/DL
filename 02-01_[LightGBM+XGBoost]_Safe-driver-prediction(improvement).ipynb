{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/92-Colab-Kaggle-ML-Classification/02-01_%5BLightGBM%2BXGBoost%5D_Safe-driver-prediction(improvement).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZmla44eMnQC"
      },
      "source": [
        "# Imformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_8PiW9AMqQh"
      },
      "source": [
        "* Title : [Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction)\n",
        "* Type : Binary Classification\n",
        "* Evaluation : Normalized Gini\n",
        "* Model : Ensemble(LightGBM, XGBoost)\n",
        "* Python version: 3.10.6\n",
        "* Basic library version\n",
        "  * sklearn(scikit-learn==1.2.2)\n",
        "  * xgboost(xgboost==1.7.6)\n",
        "  * lightgbm(lightgbm==3.3.5)\n",
        "  * bayes_opt(bayesian-optimization==1.4.3)\n",
        "  * numpy(numpy==1.22.4)\n",
        "  * pandas(pandas==1.5.3)\n",
        "  * matplotlib(matplotlib==3.7.1)\n",
        "  * seaborn(seaborn==0.12.2)\n",
        "  * missingno(missingno==0.5.2): 결측값 시각화\n",
        "  * scipy(scipy==1.10.1)\n",
        "* Addtional Library version\n",
        "* Considering Library version\n",
        "* Improvement\n",
        "  * Derived Features\n",
        "  * Adjust Hyper parameter(bayesian)\n",
        "  * XGBoost\n",
        "  * Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxkMBWDW9T3P"
      },
      "source": [
        "# STEP 0. Version check and Install Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfgM8S72TidO"
      },
      "source": [
        "Step 0-1. Install Dependency"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bayesian-optimization"
      ],
      "metadata": {
        "collapsed": true,
        "id": "l28uc4WKx7tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      },
      "source": [
        "Step 0-2. Version Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pvZ7Lm3Apv1B"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9v0TRhv5TudL"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOF78xJ1T2lL"
      },
      "source": [
        "Step 0-3. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9m2Gh7jjT5QL"
      },
      "outputs": [],
      "source": [
        "!export KAGGLE_USERNAME=*** && export KAGGLE_KEY=*** && kaggle competitions download -c porto-seguro-safe-driver-prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O8C7SzT7UlEu"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "with ZipFile(data_path + 'porto-seguro-safe-driver-prediction.zip') as zipper:\n",
        "  zipper.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TquybxQaqfE5"
      },
      "source": [
        "# STEP 1. Check Data\n",
        "\n",
        "★ 분석결과\n",
        "* ps_reg_03, ps_car_03_cat, ps_car_05_cat, ps_car_14 결측값 많음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      },
      "source": [
        "Step 1-1. Check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "data_path = '/content/'\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터 경로 설정\n",
        "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
        "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, test.shape, submission.shape"
      ],
      "metadata": {
        "id": "JmFEi8QFxIVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qlcKhOrayMWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(2)"
      ],
      "metadata": {
        "id": "xg-Dczi1JqLB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.head(2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Tmm54wizyYkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mAJQjbwW0gCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 결측값(-1) 확인\n",
        "import numpy as np\n",
        "import missingno as msno\n",
        "\n",
        "# 훈련 데이터 복사본에서 -1을 np.NaN로 변환\n",
        "train_copy = train.copy().replace(-1, np.NaN)\n",
        "\n",
        "# 결측값 시각화(처음 28개만)\n",
        "msno.bar(df=train_copy.iloc[:, 1:28], figsize=(13, 6))  # ★ ps_reg_03, ps_car_03_cat, ps_car_05_cat 결측값 많음"
      ],
      "metadata": {
        "id": "bYf0KRCm0W7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 나머지 결측값 시각화\n",
        "msno.bar(df=train_copy.iloc[:, 28:], figsize=(13, 6)) # ★ ps_car_14 결측값 존재"
      ],
      "metadata": {
        "id": "2qXlcdHv1GFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값 메트릭스\n",
        "msno.matrix(df=train_copy.iloc[:, 1:28], figsize=(13, 6))"
      ],
      "metadata": {
        "id": "xsIkQeSq1lbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 피쳐 요약표\n",
        "def resumetable(df):\n",
        "  print(f\"데이터셋 형상: {df.shape}\")\n",
        "  summary = pd.DataFrame(df.dtypes, columns=['데이터 타입'])\n",
        "  #summary = summary.reset_index()\n",
        "  #summary = summary.rename(columns={'index': '피쳐'})\n",
        "  summary['결측값 갯수'] = (df == -1).sum().values # 피처별 -1 개수(이번 데이터 특성)\n",
        "  summary['고유값 개수'] = df.nunique().values\n",
        "  summary['데이터 종류'] = None\n",
        "  for col in df.columns:\n",
        "    if 'bin' in col or col =='target':\n",
        "      summary.loc[col, '데이터 종류'] = '이진형'\n",
        "    elif 'cat' in col:\n",
        "      summary.loc[col, '데이터 종류'] = '명목형'\n",
        "    elif df[col].dtype == float:\n",
        "      summary.loc[col, '데이터 종류'] = '연속형'\n",
        "    elif df[col].dtype ==int:\n",
        "      summary.loc[col, '데이터 종류'] = '순서형'\n",
        "\n",
        "  return summary\n",
        "\n",
        "summary = resumetable(train)\n",
        "summary"
      ],
      "metadata": {
        "id": "PNKD20DFZoXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 데이터 요약표를 통한 칼럼 호출\n",
        "summary[summary['데이터 타입'] == 'float64'].index"
      ],
      "metadata": {
        "id": "t66XcFpL22bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-2. Features Info"
      ],
      "metadata": {
        "id": "myJ6kCpc0CAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "★ 분석결과\n",
        "* ps_reg_03, ps_car_03_cat, ps_car_05_cat, ps_car_14 결측값 많음"
      ],
      "metadata": {
        "id": "d7jFrfiLaePH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-3. Feature Engineering"
      ],
      "metadata": {
        "id": "gs0__czf1NiH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLz34AIjzFI_"
      },
      "source": [
        "# STEP 2. Data Visualize\n",
        "★ 분석결과\n",
        "* 타깃 피쳐\n",
        "  * 타깃값의 비율차이가 큼 → 작은 타깃값 잘 예측하는 게 중요 → 고윳값 별 타깃값 비율 확인 필요\n",
        "  * 고윳값 마다 타깃값 비율이 다르고, 신뢰구간이 좁아야 유효한 피쳐\n",
        "* 이진 피쳐\n",
        "  * ps_ind_10_bin ~ ps_ind_13_bin : 신뢰구간이 넓어서 통계적 유효성이 떨어짐 → 제거\n",
        "  * ps_calc_15_bin ~ ps_calc_20_bin : 고윳값 0, 1에 대한 타깃값 차이가 없음 → 타깃값 예측력이 없으므로 제거\n",
        "* 명목 피쳐\n",
        "  * 결측값에 대한 타깃값 비율도 신뢰구간이 넓다는 점을 감안해도 다른 값과 차이 존재 → 결측값 예측력 존재 하므로 모두 이용\n",
        "* 순서 피쳐\n",
        "  * ps_ind_14 : 타깃값 비율의 신뢰구간이 넓어 통계적 유효성이 떨어짐 → 삭제\n",
        "  * ps_calc_04 ~ ps_cal_14 : 타깃값 비율 차이 없거나 신뢰구간 넓음 → 삭제\n",
        "* 연속 피쳐\n",
        "  * ps_calc_01 ~ ps_calc_03 : 타깃값 비율 차이 없음 → 제거\n",
        "  * (상관관계) ps_car_12, ps_car_14 강한 상관관계 : ps_car_14 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2-1. Count Plot"
      ],
      "metadata": {
        "id": "pq5d4NNkANEH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A5ybi6s9V5-6"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WRhv3MIpDmyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 네모 도형 객체를 순회화며 막대 상단에 타깃값 비율 표시\n",
        "def write_percent(ax, total_size):\n",
        "  for patch in ax.patches:\n",
        "    height = patch.get_height() # 도형 높이(데이터 개수)\n",
        "    width = patch.get_width()   # 도형 너비\n",
        "    left_coord = patch.get_x()  # 도형 왼쪽 테두리의 x축 위치\n",
        "    percent = height/total_size*100\n",
        "\n",
        "    # x,y 좌표에 텍스트 입력\n",
        "    ax.text(x=left_coord + width/2.0,\n",
        "            y=height + total_size*0.001,\n",
        "            s=f'{percent:1.1f}%',\n",
        "            ha='center')"
      ],
      "metadata": {
        "id": "oWWPuSMH3UnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Count Plot : 범주형 데이터 갯수 확인\n",
        "mpl.rc('font', size=15) # 폰트 크기를 15로 설정\n",
        "plt.figure(figsize=(3, 3))\n",
        "\n",
        "# 타깃값 분포 카운트플롯\n",
        "ax = sns.countplot(x='target', data=train)\n",
        "write_percent(ax, len(train)) # 비율 표시\n",
        "ax.set_title('Target Distributuion')\n",
        "# ★ 타깃값의 비율차이가 큼 → 작은 타깃값 잘 예측하는 게 중요 → 고윳값 별 타깃값 비율 확인 필요\n",
        "# ★ 고윳값 마다 타깃값 비율이 다르고, 신뢰구간이 좁아야 유효한 피쳐"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8kVoRsDG5Mmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2-2. Binary Feature"
      ],
      "metadata": {
        "id": "0Ls0erA9APtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "### 이진 피처 Bar Plot에 타깃 비율 같이 그리기\n",
        "def plot_target_ratio_by_features(df, features, num_rows, num_cols, size=(12,18)):\n",
        "  mpl.rc('font', size=9)\n",
        "  plt.figure(figsize=size)\n",
        "  grid = gridspec.GridSpec(num_rows, num_cols)  # 서브플롯 배치\n",
        "  plt.subplots_adjust(wspace=0.3, hspace=0.3)  # 서브플롯 여백\n",
        "\n",
        "  for idx, feature in enumerate(features):\n",
        "    ax = plt.subplot(grid[idx])\n",
        "    # ax축에 고윳값별 타깃값 1 비율 막대 그래프 그리기\n",
        "    sns.barplot(x=feature, y='target', data=df, palette='Set2', ax=ax)"
      ],
      "metadata": {
        "id": "Le7gsW2W4kA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bin_features = summary[summary['데이터 종류']=='이진형'].index # 이진 피처\n",
        "plot_target_ratio_by_features(train, bin_features, num_rows=6, num_cols=3)\n",
        "\n",
        "# ★ ps_ind_10_bin ~ ps_ind_13_bin : 신뢰구간이 넓어서 통계적 유효성이 떨어짐 → 제거\n",
        "# ★ ps_calc_15_bin ~ ps_calc_20_bin : 고윳값 0, 1에 대한 타깃값 차이가 없음 → 타깃값 예측력이 없으므로 제거"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qcEOTSgr4kMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-3 Nominal Feature"
      ],
      "metadata": {
        "id": "cM8nvZ1J4kXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nom_features = summary[summary['데이터 종류']=='명목형'].index\n",
        "plot_target_ratio_by_features(train, nom_features, num_rows=7, num_cols=2)\n",
        "\n",
        "# ★ ps_ind_02_cat : 결측값에 대한 타깃값 비율 많음 → 결측값 자체가 타깃값에 대한 예측력 존재\n",
        "# ★ ps_car_02_cat : 결측값에 대한 타깃값 비율 0 → 결측값 자체가 타깃값에 대한 예측력 존재\n",
        "# ★ 그 외 결측값에 대한 타깃값 비율도 신뢰구간이 넓다는 점을 감안해도 다른 값과 차이 존재 → 결측값 예측력 존재 하므로 모두 이용"
      ],
      "metadata": {
        "id": "i4p_78CU5M9S",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-4. Orderial Feature"
      ],
      "metadata": {
        "id": "s9Fh5FwwDo2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ord_features = summary[summary['데이터 종류']=='순서형'].index\n",
        "plot_target_ratio_by_features(train, ord_features, num_rows=8, num_cols=2)\n",
        "\n",
        "# ★ ps_ind_14 : 타깃값 비율의 신뢰구간이 넓어 통계적 유효성이 떨어짐 → 삭제\n",
        "# ★ ps_calc_04 ~ ps_cal_14 : 타깃값 비율 차이 없거나 신뢰구간 넓음 → 삭제"
      ],
      "metadata": {
        "id": "58Rmad_cD0Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-5. Continuous Feature"
      ],
      "metadata": {
        "id": "cLTPPbe2Gr9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cut 함수로 연속 구간을 나눈뒤 출력\n",
        "cont_features = summary[summary['데이터 종류']=='연속형'].index\n",
        "\n",
        "plt.figure(figsize=(12, 16))\n",
        "grid = gridspec.GridSpec(5, 2)  # 서브플롯 배치\n",
        "plt.subplots_adjust(wspace=0.3, hspace=0.3)  # 서브플롯 여백\n",
        "\n",
        "for idx, cont_feature in enumerate(cont_features):\n",
        "  # 값을 5개 구간으로 나누기\n",
        "  train[cont_feature] = pd.cut(train[cont_feature], 5)\n",
        "\n",
        "  ax = plt.subplot(grid[idx])\n",
        "  sns.barplot(x=cont_feature, y='target', data=train, palette='Set2', ax=ax)\n",
        "  ax.tick_params(axis='x', labelrotation=10)\n",
        "\n",
        "# ★ ps_calc_01 ~ ps_calc_03 : 타깃값 비율 차이 없음 → 제거"
      ],
      "metadata": {
        "id": "rzHr5PS5G0al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-6. Continuous Feature(Correlation)"
      ],
      "metadata": {
        "id": "8PpcuRdtATyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# np.NaN 값 삭제\n",
        "train_copy = train_copy.dropna()"
      ],
      "metadata": {
        "id": "b_mgRmxWIPxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "cont_corr = train_copy[cont_features].corr()    # 연속형 피쳐 상관관계\n",
        "sns.heatmap(cont_corr, annot=True, cmap='OrRd') # 히트맵 그리기\n",
        "\n",
        "# ★ ps_car_12, ps_car_14 강한 상관관계 : ps_car_14 제거 후 성능 상승\n",
        "# ★ ps_reg_02, ps_reg_03 강한 상관관계 : ps_reg_03 삭제 후 성능 저하로 유지"
      ],
      "metadata": {
        "id": "dXBehwMPIP8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwqEIVGS1rtU"
      },
      "source": [
        "# STEP 3. Feature Engineering\n",
        "### ★ Add Derived Features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-1. Load Data"
      ],
      "metadata": {
        "id": "l_HvIT43CKgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "data_path = '/content/'\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터 경로 설정\n",
        "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
        "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
      ],
      "metadata": {
        "id": "6HpCCR99CKrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-2. Concat Data(Apply same feature engineering with train, test)"
      ],
      "metadata": {
        "id": "MJrEFkRoCTkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([train, test], ignore_index=True) # 훈련 데이터와 테스트 데이터 합치기\n",
        "all_data = all_data.drop('target', axis=1)  # 타깃값 제거\n",
        "all_data.tail(3)"
      ],
      "metadata": {
        "id": "QiB_GwbkCT1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features = all_data.columns # 전체 피처\n",
        "all_features"
      ],
      "metadata": {
        "id": "jDnKMZbdJXcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-3. Norminal: One-Hot Encoding"
      ],
      "metadata": {
        "id": "IujIhpsmCUAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# 명목형 피처 추출\n",
        "cat_features = [feature for feature in all_features if 'cat'in feature]\n",
        "\n",
        "onehot_encoder = OneHotEncoder()   # 원핫인코더 생성\n",
        "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])\n",
        "\n",
        "encoded_cat_matrix"
      ],
      "metadata": {
        "id": "vRNZVzkcnAVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. ★ Add Derived Features 1"
      ],
      "metadata": {
        "id": "fTqYfXJUW5au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# '데이터 하나당 결측값 개수'를 파생 피처로 추가\n",
        "all_data['num_missing'] = (all_data==-1).sum(axis=1)"
      ],
      "metadata": {
        "id": "LJo4kDeXXAo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 명목형 피처, calc 분류의 피처를 제외환 피처\n",
        "remaining_features = [feature for feature in all_features\n",
        "                      if ('cat' not in feature and 'calc' not in feature)]\n",
        "# num_missing을 remaining_features에 추가\n",
        "remaining_features.append('num_missing')"
      ],
      "metadata": {
        "id": "lEIFC2qMXbkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. ★ Add Derived Features 2"
      ],
      "metadata": {
        "id": "eapjiFhTXw9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류가 ind인 피처를 연결해서 새로운 ㅣㅍ처로\n",
        "ind_features = [feature for feature in all_features if 'ind' in feature]\n",
        "\n",
        "is_first_feature = True\n",
        "for ind_feature in ind_features:\n",
        "  if is_first_feature:\n",
        "    all_data['mix_ind'] = all_data[ind_feature].astype(str) + '_'\n",
        "    is_first_feature = False\n",
        "  else:\n",
        "    all_data['mix_ind'] +=  all_data[ind_feature].astype(str) + '_'\n",
        "\n",
        "all_data['mix_ind']"
      ],
      "metadata": {
        "id": "Uk2nw938XzXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data['ps_ind_02_cat'].value_counts()"
      ],
      "metadata": {
        "id": "5ey-NTiEmcXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data['ps_ind_02_cat'].value_counts().to_dict()"
      ],
      "metadata": {
        "id": "yXg07Jdzmh3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 명목형 피처의 고윳값별 개수를 새로운 피처로\n",
        "cat_count_features = []\n",
        "for feature in cat_features+['mix_ind']:\n",
        "  val_counts_dict = all_data[feature].value_counts().to_dict()\n",
        "  all_data[f'{feature}_count'] = all_data[feature].apply(lambda x: val_counts_dict[x])\n",
        "\n",
        "  cat_count_features.append(f'{feature}_count')\n",
        "\n",
        "cat_count_features"
      ],
      "metadata": {
        "id": "lrVf5S1Dmn5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. Remove Feature"
      ],
      "metadata": {
        "id": "0o-Eo49JJ3W7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 불필요한 피처\n",
        "drop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n",
        "\n",
        "all_data_remaining = all_data[remaining_features + cat_count_features].drop(drop_features, axis=1)"
      ],
      "metadata": {
        "id": "gjlYI-xMJ5qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-5. Merge Feature"
      ],
      "metadata": {
        "id": "TyJNYT5sKzTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining),\n",
        "                               encoded_cat_matrix],\n",
        "                              format='csr')"
      ],
      "metadata": {
        "id": "WwBQwjofK2b8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-6. Divide Data(train, test, valid)"
      ],
      "metadata": {
        "id": "2jOT_t9EE6X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = len(train)  # 훈련 데이터 개수\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 나누기\n",
        "X = all_data_sprs[:num_train]\n",
        "X_test = all_data_sprs[num_train:]\n",
        "\n",
        "y = train['target'].values"
      ],
      "metadata": {
        "id": "81ISFus2E6jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4. Evaluation Function"
      ],
      "metadata": {
        "id": "jBC8EeFJLrco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 정규화된 지니계수\n",
        "import numpy as np\n",
        "\n",
        "def eval_gini(y_true, y_pred):\n",
        "  # 실제값과 예측값의 크기가 같은지 서로 확인(다르면 오류)\n",
        "  assert y_true.shape == y_pred.shape\n",
        "\n",
        "  n_samples = y_true.shape[0]                       # 데이터 개수\n",
        "  L_mid = np.linspace(1 / n_samples, 1, n_samples)  # 대각선 값\n",
        "\n",
        "  # 1) 예측값에 대한 지니계수\n",
        "  pred_order = y_true[y_pred.argsort()] # y_pred 크기 순으로 y_true 값 정렬\n",
        "  L_pred = np.cumsum(pred_order) / np.sum(pred_order) # 로렌츠 곡선\n",
        "  G_pred = np.sum(L_mid - L_pred) # 예측값에 대한 지니 계수\n",
        "\n",
        "  # 2) 예측이 완벽할 때 지니계수\n",
        "  true_order = y_true[y_true.argsort()] # y_true 크기 순으로 y_true 값 정렬\n",
        "  L_true = np.cumsum(true_order) / np.sum(true_order)  # 로렌츠 곡선\n",
        "  G_true = np.sum(L_mid - L_true) # 예측값이 완벽할 때 지니계수\n",
        "\n",
        "  # 정규화된 지니계수\n",
        "  return G_pred / G_true"
      ],
      "metadata": {
        "id": "vWAj3a-yLuFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM용 gini() 함수\n",
        "def gini(preds, dtrain):\n",
        "  labels = dtrain.get_label()\n",
        "  return 'gini', eval_gini(labels, preds), True   # 평가지표 이름, 평가점수, 평가 점수가 높을수록 좋은지 여부"
      ],
      "metadata": {
        "id": "8Vhb7-k5MxDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4. Model(LightGBM)\n",
        "### ★ Adjust Hyper parameter(bayesian)"
      ],
      "metadata": {
        "id": "BDwpbveiFn07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "rmWF-7pEFn_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-2. ★ Adjust Hyper parameter(bayesian)"
      ],
      "metadata": {
        "id": "FfCeKb2roNce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 베이지안 최적화를 위한 데이터셋 준비\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
        "                                                      test_size=0.2,\n",
        "                                                      random_state=0)\n",
        "# 베이지안 최적화용 데이터셋\n",
        "bayes_dtrain = lgb.Dataset(X_train, y_train)\n",
        "bayes_dvalid = lgb.Dataset(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "Fmvzw6zVocHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 베이지안 최적화를 위한 하이퍼 파라미터 범위\n",
        "param_bounds = {'num_leaves': (30, 40),\n",
        "                'lambda_l1': (0.7, 0.9),\n",
        "                'lambda_l2': (0.9, 1),\n",
        "                'feature_fraction': (0.6, 0.7),\n",
        "                'bagging_fraction': (0.6, 0.9),\n",
        "                'min_child_samples': (6, 10),\n",
        "                'min_child_weight': (10, 40)}\n",
        "\n",
        "# 값이 고정된 하이퍼 파라미터\n",
        "fixed_params = {'objective':'binary',\n",
        "                'learning_rate': 0.005,\n",
        "                'bagging_freq': 1,\n",
        "                'force_row_wise': True,\n",
        "                'random_state': 1991}"
      ],
      "metadata": {
        "id": "Ps2R7JtzozkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 베이지안 최적화용 평가지표 계산함수 작성\n",
        "def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction,\n",
        "                  bagging_fraction, min_child_samples, min_child_weight):\n",
        "  '''최적화하려는 평가지표(지니계수) 계산 함수'''\n",
        "\n",
        "  # 베이지안 최적화를 수행할 하이퍼파라미터\n",
        "  params = {'num_leaves': int(round(num_leaves)),\n",
        "            'lambda_l1': lambda_l1,\n",
        "            'lambda_l2': lambda_l2,\n",
        "            'feature_fraction': feature_fraction,\n",
        "            'bagging_fraction': bagging_fraction,\n",
        "            'min_child_samples': int(round(min_child_samples)),\n",
        "            'min_child_weight': min_child_weight,\n",
        "            'feature_pre_filter': False}\n",
        "  # 고정된 하이퍼파라미터 추가\n",
        "  params.update(fixed_params)\n",
        "\n",
        "  print('하이퍼파라미터:', params)\n",
        "\n",
        "  # LightGBM 모델 훈련\n",
        "  lgb_model = lgb.train(params=params,\n",
        "                        train_set=bayes_dtrain,\n",
        "                        num_boost_round=2500,\n",
        "                        valid_sets=bayes_dvalid,\n",
        "                        feval=gini,\n",
        "                        early_stopping_rounds=300,\n",
        "                        verbose_eval=False)\n",
        "  # 검증 데이터로 예측 수행\n",
        "  preds = lgb_model.predict(X_valid)\n",
        "  # 지니계수 계산\n",
        "  gini_score = eval_gini(y_valid, preds)\n",
        "  print(f\"지니계수: {gini_score}\\n\")\n",
        "\n",
        "  return gini_score"
      ],
      "metadata": {
        "id": "wdMYKwKqpdZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적화 수행\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# 베이지안 최적화 객체 생성\n",
        "optimizer = BayesianOptimization(f=eval_function,       # 평가지표 계산함수\n",
        "                                 pbounds=param_bounds,  # 하이퍼파라미터 범위\n",
        "                                 random_state=0)\n",
        "\n",
        "# 베이지안 최적화 수행\n",
        "optimizer.maximize(init_points=3, n_iter=6)"
      ],
      "metadata": {
        "id": "Z_FXflQysIsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가함수 점수가 최대일 때 하이퍼파라미터\n",
        "max_params = optimizer.max['params']\n",
        "max_params"
      ],
      "metadata": {
        "id": "d0AtIlRnst46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수형 하이퍼파라미터 변환\n",
        "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
        "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
        "# 고정된 하이퍼파마리터 추가\n",
        "max_params.update(fixed_params)\n",
        "\n",
        "max_params"
      ],
      "metadata": {
        "id": "u9o9_04Ws1rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5. Learning(LightGBM)"
      ],
      "metadata": {
        "id": "XPEeIrtQGJIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5-1. Setting"
      ],
      "metadata": {
        "id": "5gB6dvLlGJS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# K 폴드 교차 검증기\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n",
        "\n",
        "\"\"\"삭제(베이지안 최적파라미터 사용)\n",
        "# LightGBM 하이퍼파라미터 설정\n",
        "params = {'objective':'binary',\n",
        "          'learning_rate':0.01,\n",
        "          'force_row_wise':True,  # 경고 문구 제거\n",
        "          'random_state':0}\n",
        "\"\"\"\n",
        "\n",
        "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
        "oof_val_preds = np.zeros(X.shape[0])\n",
        "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
        "oof_test_preds = np.zeros(X_test.shape[0])"
      ],
      "metadata": {
        "id": "iaOEqUK4GJaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5-2. Learning(OOF)"
      ],
      "metadata": {
        "id": "uMmENV_FGPBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OOF 방식으로 모델 훈련, 검증, 예측\n",
        "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "  # 각 폴드를 구분하는 문구 출력\n",
        "  print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
        "\n",
        "  # 훈련용 데이터, 검증용 데이터 설정\n",
        "  X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n",
        "  X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n",
        "\n",
        "  # LightGBM 전용 데이터셋 생성\n",
        "  dtrain = lgb.Dataset(X_train, y_train)\n",
        "  dvalid = lgb.Dataset(X_valid, y_valid)\n",
        "\n",
        "  # LightGBM 모델 훈련\n",
        "  lgb_model = lgb.train(params=max_params,      # ★ 베이지안 최적 하이퍼파라미터\n",
        "                        train_set=dtrain,       # 훈련 데이터셋\n",
        "                        num_boost_round=1000,   # 부스팅 반복 횟수\n",
        "                        valid_sets=dvalid,      # 검증 데이터셋\n",
        "                        feval=gini,             # 평가지표\n",
        "                        early_stopping_rounds=100,  # 조기종료 조건\n",
        "                        verbose_eval=100)       # 100번째마다 점수 출력\n",
        "\n",
        "  # 테스트 데이터를 활용해 OOF 예측\n",
        "  oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n",
        "  # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n",
        "  oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
        "\n",
        "  # 검증 데이터 예측 확률에 대한 정규화 지니계수\n",
        "  gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n",
        "  print(f\"폴드 {idx+1} 지니계수: {gini_score}\\n\")"
      ],
      "metadata": {
        "id": "2Z71NNIGGPKQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds))"
      ],
      "metadata": {
        "id": "L4tVgaKC4wdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_test_preds_lgb = oof_test_preds\n",
        "oof_test_preds_lgb"
      ],
      "metadata": {
        "id": "hw7u8na8xx6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6. ★ Model(XGBoost)"
      ],
      "metadata": {
        "id": "0DvievmXt9fY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6-1. Evaluation Function"
      ],
      "metadata": {
        "id": "_yBJJ8h5ue9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost용 gini() 함수\n",
        "def gini(preds, dtrain):\n",
        "  labels = dtrain.get_label()\n",
        "  return 'gini', eval_gini(labels, preds)"
      ],
      "metadata": {
        "id": "KkqRQ_lzt9YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6-2. Model"
      ],
      "metadata": {
        "id": "3OaBLtZyu6sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "rjSU_lL5u6Dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6-3. Otpimize HyperParameters(Bayesian)"
      ],
      "metadata": {
        "id": "A5HTBbeYuhwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 베이지안 최적화를 위한 데이터셋 준비\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
        "                                                      test_size=0.2,\n",
        "                                                      random_state=0)\n",
        "# 베이지안 최적화용 데이터셋\n",
        "bayes_dtrain = xgb.DMatrix(X_train, y_train)\n",
        "bayes_dvalid = xgb.DMatrix(X_valid, y_valid)"
      ],
      "metadata": {
        "id": "st8pv3dWu32d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 베이지안 최적화를 위한 하이퍼 파라미터 범위\n",
        "param_bounds = {'max_depth': (4, 8),\n",
        "                'subsample': (0.6, 0.9),\n",
        "                'colsample_bytree': (0.7, 1.0),\n",
        "                'min_child_weight': (5, 7),\n",
        "                'gamma': (8, 11),\n",
        "                'reg_alpha': (7, 9),\n",
        "                'reg_lambda': (1.1, 1.5),\n",
        "                'scale_pos_weight': (1.4, 1.6)}\n",
        "\n",
        "# 값이 고정된 하이퍼 파라미터\n",
        "fixed_params = {'objective':'binary:logistic',\n",
        "                'learning_rate': 0.02,\n",
        "                'random_state': 1991}"
      ],
      "metadata": {
        "id": "282zwxGnu32k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 베이지안 최적화용 평가지표 계산함수 작성\n",
        "def eval_function(max_depth, subsample, colsample_bytree, min_child_weight,\n",
        "                  reg_alpha, gamma, reg_lambda, scale_pos_weight):\n",
        "  '''최적화하려는 평가지표(지니계수) 계산 함수'''\n",
        "\n",
        "  # 베이지안 최적화를 수행할 하이퍼파라미터\n",
        "  params = {'max_depth': int(round(max_depth)),\n",
        "            'subsample': subsample,\n",
        "            'colsample_bytree': colsample_bytree,\n",
        "            'min_child_weight': min_child_weight,\n",
        "            'gamma': gamma,\n",
        "            'reg_alpha': reg_alpha,\n",
        "            'reg_lambda': reg_lambda,\n",
        "            'scale_pos_weight': scale_pos_weight}\n",
        "  # 고정된 하이퍼파라미터 추가\n",
        "  params.update(fixed_params)\n",
        "\n",
        "  print('하이퍼파라미터:', params)\n",
        "\n",
        "  # XGBoost 모델 훈련\n",
        "  xgb_model = xgb.train(params=params,\n",
        "                        dtrain=bayes_dtrain,\n",
        "                        num_boost_round=2000,\n",
        "                        evals=[(bayes_dvalid, 'bayes_dvalid')],\n",
        "                        maximize=True,\n",
        "                        feval=gini,\n",
        "                        early_stopping_rounds=200,\n",
        "                        verbose_eval=False\n",
        "                        )\n",
        "\n",
        "  best_iter = xgb_model.best_iteration  # 최적 반복 횟수\n",
        "\n",
        "  # 검증 데이터로 예측 수행\n",
        "  preds = xgb_model.predict(bayes_dvalid, iteration_range=(0, best_iter))\n",
        "  # 지니계수 계산\n",
        "  gini_score = eval_gini(y_valid, preds)\n",
        "  print(f\"지니계수: {gini_score}\\n\")\n",
        "\n",
        "  return gini_score"
      ],
      "metadata": {
        "id": "aMQ1ANadu32k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적화 수행\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "# 베이지안 최적화 객체 생성\n",
        "optimizer = BayesianOptimization(f=eval_function,       # 평가지표 계산함수\n",
        "                                 pbounds=param_bounds,  # 하이퍼파라미터 범위\n",
        "                                 random_state=0)\n",
        "\n",
        "# 베이지안 최적화 수행\n",
        "optimizer.maximize(init_points=3, n_iter=6)"
      ],
      "metadata": {
        "id": "8GftxsXSu32k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가함수 점수가 최대일 때 하이퍼파라미터\n",
        "max_params = optimizer.max['params']\n",
        "max_params"
      ],
      "metadata": {
        "id": "O9Mhgrebu32k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수형 하이퍼파라미터 변환\n",
        "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
        "# 고정된 하이퍼파마리터 추가\n",
        "max_params.update(fixed_params)\n",
        "\n",
        "max_params"
      ],
      "metadata": {
        "id": "ZwYwznDAu32k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 7. ★ Learning(XGBoost)"
      ],
      "metadata": {
        "id": "F9Tk_uH0t9Ls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7-1. Setting"
      ],
      "metadata": {
        "id": "0Wzzqx4VxeCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# K 폴드 교차 검증기\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n",
        "\n",
        "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
        "oof_val_preds = np.zeros(X.shape[0])\n",
        "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
        "oof_test_preds = np.zeros(X_test.shape[0])"
      ],
      "metadata": {
        "id": "3IbgcahlxeCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5-2. Learning(OOF)"
      ],
      "metadata": {
        "id": "OINjjjYlxeCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OOF 방식으로 모델 훈련, 검증, 예측\n",
        "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "  # 각 폴드를 구분하는 문구 출력\n",
        "  print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
        "\n",
        "  # 훈련용 데이터, 검증용 데이터 설정\n",
        "  X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n",
        "  X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n",
        "\n",
        "  # XGBoost 전용 데이터셋 생성\n",
        "  dtrain = xgb.DMatrix(X_train, y_train)\n",
        "  dvalid = xgb.DMatrix(X_valid, y_valid)\n",
        "  dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "  # XGBoost 모델 훈련\n",
        "  xgb_model = xgb.train(params=max_params,\n",
        "                        dtrain=dtrain,\n",
        "                        num_boost_round=2000,\n",
        "                        evals=[(dvalid, 'valid')],\n",
        "                        maximize=True,\n",
        "                        feval=gini,\n",
        "                        early_stopping_round=200,\n",
        "                        verbose_eval=100)\n",
        "\n",
        "  # 모델 성능 가장 좋을 때의 부스팅 반복 횟수 저장\n",
        "  best_iter = xgb_model.best_iteration\n",
        "\n",
        "  # 테스트 데이터를 활용해 OOF 예측\n",
        "  oof_test_preds += xgb_model.predict(dtest, iteration_range=(0, best_iter))/folds.n_splits\n",
        "  # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n",
        "  oof_val_preds[valid_idx] += xgb_model.predict(dvalid, iteration_range=(0, best_iter))\n",
        "\n",
        "  # 검증 데이터 예측 확률에 대한 정규화 지니계수\n",
        "  gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n",
        "  print(f\"폴드 {idx+1} 지니계수: {gini_score}\\n\")"
      ],
      "metadata": {
        "id": "7JL2AyisxeCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds))"
      ],
      "metadata": {
        "id": "-7jE-vkt5eV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oof_test_preds_xgb = oof_test_preds\n",
        "oof_test_preds_xgb"
      ],
      "metadata": {
        "id": "R_uCRzd1uPM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TzxvoFCAZT7"
      },
      "source": [
        "# STEP 8. Ensemble and Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6-1. Ensemble"
      ],
      "metadata": {
        "id": "Iwjg_6nsH2gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oof_test_preds = oof_test_preds_lgb * 0.5 + oof_test_preds_xgb * 0.5"
      ],
      "metadata": {
        "id": "3r6IKVNNy7vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrKX3dBvF5Ib"
      },
      "source": [
        "Step 6-2. Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7NJo_4fF6U-"
      },
      "outputs": [],
      "source": [
        "submission['target'] = oof_test_preds\n",
        "submission.to_csv('submission.csv')   # 제출 파일 생성"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}