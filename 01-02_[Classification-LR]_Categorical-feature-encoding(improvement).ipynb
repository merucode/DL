{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/92-Colab-Kaggle-ML-Classification/01-02_%5BClassification-LR%5D_Categorical-feature-encoding(improvement).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZmla44eMnQC"
      },
      "source": [
        "# Imformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_8PiW9AMqQh"
      },
      "source": [
        "* Title : [Categorical Feature Encoding](https://www.kaggle.com/c/cat-in-the-dat)\n",
        "* Type : Binary Classification\n",
        "* Evaluation : ROC AUC\n",
        "* Model : Logistic Regresion\n",
        "* Python version: 3.10.6\n",
        "* Basic library version\n",
        "  * sklearn(scikit-learn==1.2.2)\n",
        "  * numpy(numpy==1.22.4)\n",
        "  * pandas(pandas==1.5.3)\n",
        "  * matplotlib(matplotlib==3.7.1)\n",
        "  * seaborn(seaborn==0.12.2)\n",
        "  * scipy(scipy==1.10.1)\n",
        "* Addtional Library version\n",
        "* Considering Library version\n",
        "* Improvement\n",
        "  * Feature Set Encoding\n",
        "  * Feature Scaling\n",
        "  * Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxkMBWDW9T3P"
      },
      "source": [
        "# STEP 0. Version check and Install Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfgM8S72TidO"
      },
      "source": [
        "Step 0-1. Install Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      },
      "source": [
        "Step 0-2. Version Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pvZ7Lm3Apv1B"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9v0TRhv5TudL"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOF78xJ1T2lL"
      },
      "source": [
        "Step 0-3. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9m2Gh7jjT5QL"
      },
      "outputs": [],
      "source": [
        "!export KAGGLE_USERNAME=*** && export KAGGLE_KEY=*** && kaggle competitions download -c cat-in-the-dat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O8C7SzT7UlEu"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "with ZipFile(data_path + 'cat-in-the-dat.zip') as zipper:\n",
        "  zipper.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TquybxQaqfE5"
      },
      "source": [
        "# STEP 1. Check Data\n",
        "\n",
        "★ 분석결과\n",
        "* 이진 피쳐\n",
        "  * bin_3: T → 1, F → 0 인코딩\n",
        "  * bin_4: Y → 1, N → 0 인코딩\n",
        "* 순서형 피쳐\n",
        "  * 고윳값 순서에 맞게 인코딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      },
      "source": [
        "Step 1-1. Check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "data_path = '/content/'\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터 경로 설정\n",
        "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
        "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape, test.shape, submission.shape"
      ],
      "metadata": {
        "id": "JmFEi8QFxIVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head().T"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qlcKhOrayMWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head().T"
      ],
      "metadata": {
        "id": "xg-Dczi1JqLB",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.head()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Tmm54wizyYkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mAJQjbwW0gCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 피쳐 요약표\n",
        "def resumetable(df):\n",
        "  print(f\"데이터셋 형상: {df.shape}\")\n",
        "  summary = pd.DataFrame(df.dtypes, columns=['데이터 타입'])\n",
        "  summary = summary.reset_index()\n",
        "  summary = summary.rename(columns={'index': '피쳐'})\n",
        "  summary['결측값 갯수'] = df.isnull().sum().values\n",
        "  summary['고유값 개수'] = df.nunique().values\n",
        "  summary['첫 번째 값'] = df.loc[0].values\n",
        "  summary['두 번째 값'] = df.loc[1].values\n",
        "  summary['세 번째 값'] = df.loc[2].values\n",
        "\n",
        "  return summary\n",
        "\n",
        "resumetable(train)"
      ],
      "metadata": {
        "id": "PNKD20DFZoXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 순서형 데이터 고윳값 확인\n",
        "for i in range(3):\n",
        "  feature = 'ord_' + str(i)\n",
        "  print(f'{feature} 고윳값: {train[feature].unique()}')\n",
        "\n",
        "for i in range(3, 6):\n",
        "  feature = 'ord_' + str(i)\n",
        "  print(f'{feature} 고윳값: {train[feature].unique()}')"
      ],
      "metadata": {
        "id": "4PNUxcHtbEE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 그 외 데이터 고윳값 확인\n",
        "check_list = ['day', 'month', 'target']\n",
        "for i in check_list:\n",
        "  print(f'{i} 고윳값: {train[i].unique()}')"
      ],
      "metadata": {
        "id": "INIWs3jAbrhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-2. Features Info"
      ],
      "metadata": {
        "id": "myJ6kCpc0CAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 이진 피쳐 : bin_0 ~ bin_4\n",
        "* 명목형 피쳐 : nom_0 ~ nom_9\n",
        "* 순서형 피쳐 : ord_0 ~ ord_5\n",
        "* 그 외 피쳐 : day, month, target\n",
        "\n",
        "★ 분석결과\n",
        "* 이진 피쳐\n",
        "  * bin_3: T → 1, F → 0 인코딩\n",
        "  * bin_4: Y → 1, N → 0 인코딩\n",
        "* 순서형 피쳐\n",
        "  * 고윳값 순서에 맞게 인코딩"
      ],
      "metadata": {
        "id": "d7jFrfiLaePH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-3. Feature Engineering"
      ],
      "metadata": {
        "id": "gs0__czf1NiH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLz34AIjzFI_"
      },
      "source": [
        "# STEP 2. Data Visualize\n",
        "★ 분석결과\n",
        "* day, month : 원-핫 인코딩 필요"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2-1. Count Plot"
      ],
      "metadata": {
        "id": "pq5d4NNkANEH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A5ybi6s9V5-6"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Count Plot : 범주형 데이터 갯수 확인\n",
        "mpl.rc('font', size=15) # 폰트 크기를 15로 설정\n",
        "plt.figure(figsize=(3, 3))\n",
        "\n",
        "# 타깃값 분포 카운트플롯\n",
        "ax = sns.countplot(x='target', data=train)\n",
        "ax.set_title('Target Distributuion')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8kVoRsDG5Mmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 네모 도형 객체를 순회화며 막대 상단에 타깃값 비율 표시\n",
        "def write_percent(ax, total_size):\n",
        "  for patch in ax.patches:\n",
        "    height = patch.get_height() # 도형 높이(데이터 개수)\n",
        "    width = patch.get_width()   # 도형 너비\n",
        "    left_coord = patch.get_x()  # 도형 왼쪽 테두리의 x축 위치\n",
        "    percent = height/total_size*100\n",
        "\n",
        "    # x,y 좌표에 텍스트 입력\n",
        "    ax.text(x=left_coord + width/2.0,\n",
        "            y=height + total_size*0.001,\n",
        "            s=f'{percent:1.1f}%',\n",
        "            ha='center')"
      ],
      "metadata": {
        "id": "MBUN2ug_ez5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2-2. Bar Plot"
      ],
      "metadata": {
        "id": "0Ls0erA9APtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.gridspec as gridspec # 여러 그래프를 격자 형태로 배치\n",
        "### BAR PLOT : 범주형 데이터에 따른 수치형 데이터 정보\n",
        "\n",
        "# m행 n열 Figure 준비\n",
        "mpl.rc('font', size=12)       # 폰트 크기 설정\n",
        "grid = gridspec.GridSpec(3,2) # 그래프 3*2 배치\n",
        "plt.figure(figsize=(10, 16))\n",
        "plt.subplots_adjust(wspace=0.4, hspace=0.3) # 서브플롯 간 좌우/상하 여백 설정\n",
        "\n",
        "# 서브플롯 그리기\n",
        "bin_features = ['bin_0', 'bin_1', 'bin_2', 'bin_3', 'bin_4']  # 피처 목록\n",
        "\n",
        "for idx, feature in enumerate(bin_features):\n",
        "  ax = plt.subplot(grid[idx])\n",
        "\n",
        "  # ax축에 타깃값 분포 카운트플롯 그리기\n",
        "  sns.countplot(x=feature,\n",
        "                data=train,\n",
        "                hue='target',\n",
        "                palette='pastel',\n",
        "                ax=ax)\n",
        "\n",
        "  ax.set_title(f'{feature} Distribution by Target')\n",
        "  write_percent(ax, len(train))"
      ],
      "metadata": {
        "id": "i4p_78CU5M9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-3. 교차분석표"
      ],
      "metadata": {
        "id": "8PpcuRdtATyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Cross-tabulation: 범주형 데이터 2개를 비교 분석\n",
        "# 교차분석표 df 생성 함수 정의\n",
        "def get_crosstab(df, feature):\n",
        "  crosstab = pd.crosstab(df[feature], df['target'], normalize='index') * 100\n",
        "  crosstab = crosstab.reset_index()\n",
        "  return crosstab"
      ],
      "metadata": {
        "id": "7NYp4aElfyZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Point Plot 함수 정의\n",
        "\n",
        "def plot_pointplot(ax, feature, crosstab): # 카운트플롯이 그려진 축에 포인트플롯 중복으로 그리는 함수\n",
        "  ax2 = ax.twinx()  # x축은 공유하고 y축은 공유하지 않는 새로운 축 생성\n",
        "  # 새로운 축에 포인트플롯 그리기\n",
        "  ax2 = sns.pointplot(x=feature, y=1, data=crosstab,\n",
        "                      order=crosstab[feature].values, # 포인트플롯 순서\n",
        "                      color='black')\n",
        "  ax2.set_ylim(crosstab[1].min()-5, crosstab[1].max()*1.1)  # y축 범위 설정\n",
        "  ax2.set_ylabel('Target 1 Ratio(%)')"
      ],
      "metadata": {
        "id": "xiaHwfVgf0Sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 피처분포도 및 피처별 타깃값 1의 비율 포인트플롯 생성함수 만들기\n",
        "def plot_cat_dist_with_true_ratio(df, features, num_rows, num_cols, size=(15,20)):\n",
        "  plt.figure(figsize=size)  # Figure 크기\n",
        "  grid = gridspec.GridSpec(num_rows, num_cols)  # 서브플롯 배치\n",
        "  plt.subplots_adjust(wspace=0.45, hspace=0.3)  # 서브플롯 여백\n",
        "\n",
        "  for idx, feature in enumerate(features):\n",
        "    ax = plt.subplot(grid[idx])\n",
        "    crosstab = get_crosstab(df, feature)  # 교차분석표 생성\n",
        "\n",
        "    # ax축에 타깃값 분포 카운트플롯 그리기\n",
        "    sns.countplot(x=feature, data=df,\n",
        "                  order=crosstab[feature].values,\n",
        "                  color='skyblue',\n",
        "                  ax=ax)\n",
        "    write_percent(ax, len(df))  # 비율 표시\n",
        "\n",
        "    plot_pointplot(ax, feature, crosstab) # 포인트플롯 그리기\n",
        "\n",
        "    ax.set_title(f'{feature} Distribution')"
      ],
      "metadata": {
        "id": "_joJ0CvAf0am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nom_features = ['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4']\n",
        "plot_cat_dist_with_true_ratio(train, nom_features, num_rows=3, num_cols=2)"
      ],
      "metadata": {
        "id": "uHR321o4f5_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ord_features = ['ord_0', 'ord_1', 'ord_2', 'ord_3'] # 순서대로 정렬되어 있지 않음\n",
        "\n",
        "plot_cat_dist_with_true_ratio(train, ord_features, num_rows=2, num_cols=2, size=(10,10))"
      ],
      "metadata": {
        "id": "WD26KofEf0ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### ord_feature 순서대로 정렬\n",
        "from pandas.api.types import CategoricalDtype\n",
        "\n",
        "ord_1_value = ['Novice', 'Contributor', 'Expert', 'Master', 'Grandmaster']\n",
        "ord_2_value = ['Freezing', 'Cold', 'Warm', 'Hot', 'Boiling Hot', 'Lava Hot']\n",
        "\n",
        "# 순서를 지정한 범주형 데이터 타입\n",
        "ord_1_dtype = CategoricalDtype(categories=ord_1_value, ordered=True)\n",
        "ord_2_dtype = CategoricalDtype(categories=ord_2_value, ordered=True)\n",
        "\n",
        "# 데이터 타입 변경\n",
        "train['ord_1'] = train['ord_1'].astype(ord_1_dtype)\n",
        "train['ord_2'] = train['ord_2'].astype(ord_2_dtype)\n",
        "\n",
        "plot_cat_dist_with_true_ratio(train, ord_features, num_rows=2, num_cols=2, size=(10,10))"
      ],
      "metadata": {
        "id": "CfGbOG-xf0tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ym2BV53TlFvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_cat_dist_with_true_ratio(train, ['ord_4', 'ord_5'], num_rows=2, num_cols=1, size=(15,12))"
      ],
      "metadata": {
        "id": "wnF8r_T8kVXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_features = ['day', 'month']\n",
        "plot_cat_dist_with_true_ratio(train, date_features, num_rows=2, num_cols=1, size=(10,10))"
      ],
      "metadata": {
        "id": "fkBak3oIkVlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-7. ★ 분석결과"
      ],
      "metadata": {
        "id": "XDDprCTBBxB2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* day, month : 원-핫 인코딩 필요"
      ],
      "metadata": {
        "id": "VQMjMy8M5pCE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwqEIVGS1rtU"
      },
      "source": [
        "# STEP 3. Feature Engineering\n",
        "### ★ Feature Set Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-1. Load Data"
      ],
      "metadata": {
        "id": "l_HvIT43CKgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "data_path = '/content/'\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터 경로 설정\n",
        "train = pd.read_csv(data_path + 'train.csv', index_col='id')\n",
        "test = pd.read_csv(data_path + 'test.csv', index_col='id')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')"
      ],
      "metadata": {
        "id": "6HpCCR99CKrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-2. Concat Data(Apply same feature engineering with train, test)"
      ],
      "metadata": {
        "id": "MJrEFkRoCTkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([train, test]) # 훈련 데이터와 테스트 데이터 합치기\n",
        "all_data = all_data.drop('target', axis=1)  # 타깃값 제거\n",
        "all_data.tail(3)"
      ],
      "metadata": {
        "id": "QiB_GwbkCT1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-3. ★ Binary Set Encoding"
      ],
      "metadata": {
        "id": "FCfnz4cEq9zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data['bin_3'] = all_data['bin_3'].map({'F':0, 'T':1})\n",
        "all_data['bin_4'] = all_data['bin_4'].map({'N':0, 'Y':1})"
      ],
      "metadata": {
        "id": "qng2PFAmq9qP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. ★ Ord Set Encoding"
      ],
      "metadata": {
        "id": "a_LUHpiTq9hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ord1dict = {'Novice':0, 'Contributor':1, 'Expert':2, 'Master':3, 'Grandmaster':4}\n",
        "ord2dict = {'Freezing':0, 'Cold':1, 'Warm':2, 'Hot':3, 'Boiling Hot':4, 'Lava Hot':5}\n",
        "\n",
        "all_data['ord_1'] = all_data['ord_1'].map(ord1dict)\n",
        "all_data['ord_2'] = all_data['ord_2'].map(ord2dict)"
      ],
      "metadata": {
        "id": "5GbaKcaKq9SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "ord_345 = ['ord_3', 'ord_4', 'ord_5']\n",
        "\n",
        "ord_encoder = OrdinalEncoder()  # OrdinalEncoder 객체 생성\n",
        "# ordinal 인코딩 적용\n",
        "all_data[ord_345] = ord_encoder.fit_transform(all_data[ord_345])\n",
        "\n",
        "# 피처별 인코딩 순서 출력\n",
        "for feature, categories in zip(ord_345, ord_encoder.categories_):\n",
        "  print(feature)\n",
        "  print(categories)"
      ],
      "metadata": {
        "id": "cel0nJfUrfvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-5. Nom Set Encoder(One-Hot Encoding)"
      ],
      "metadata": {
        "id": "IujIhpsmCUAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nom_features = ['nom_' + str(i) for i in range(10)]\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "onehot_encoder = OneHotEncoder()   # 원핫인코더 생성\n",
        "\n",
        "# all_data[nom_features] = onehot_encoder.fit_transform(all_data[nom_features]) # 오류 발생(곧바로 인코딩X)\n",
        "encoded_nom_matrix = onehot_encoder.fit_transform(all_data[nom_features])\n",
        "\n",
        "encoded_nom_matrix"
      ],
      "metadata": {
        "id": "vRNZVzkcnAVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기존 데이터의 기존 명목형 피쳐 삭제(Onehot 인코더에 모두 정보 들어있기 때문에)\n",
        "all_data = all_data.drop(nom_features, axis=1)"
      ],
      "metadata": {
        "id": "XCwTEbvVuRzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-6. ETC Set Encoder(One-Hot Encoding)"
      ],
      "metadata": {
        "id": "ZPziyoD2uJPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "date_features = ['day', 'month']\n",
        "\n",
        "encoded_date_matrix = onehot_encoder.fit_transform(all_data[date_features])\n",
        "\n",
        "all_data = all_data.drop(date_features, axis=1)\n",
        "\n",
        "encoded_date_matrix"
      ],
      "metadata": {
        "id": "nu1m8IIVukgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-7. ★ Feature Scaling"
      ],
      "metadata": {
        "id": "lNVZVyEJu55R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 순서형 min-max 정규화\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "ord_features = ['ord_' + str(i) for i in range(6)]\n",
        "# min-max 정규화\n",
        "all_data[ord_features] = MinMaxScaler().fit_transform(all_data[ord_features])"
      ],
      "metadata": {
        "id": "LU_eTNMxu9AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-8. ★ Merge Features"
      ],
      "metadata": {
        "id": "6njOq-XFvnio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import sparse\n",
        "\n",
        "# 인코딩 및 스케일링 된 피처 합치기 > 모두 CSR 전환\n",
        "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data),\n",
        "                               encoded_nom_matrix,\n",
        "                               encoded_date_matrix],\n",
        "                              format='csr')\n",
        "\n",
        "all_data_sprs"
      ],
      "metadata": {
        "id": "7ht4HnEYv8lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. Divide Data(train, test, valid)"
      ],
      "metadata": {
        "id": "2jOT_t9EE6X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = len(train)  # 훈련 데이터 개수\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터 나누기\n",
        "X_train = all_data_sprs[:num_train]\n",
        "X_test = all_data_sprs[num_train:]\n",
        "\n",
        "y = train['target']"
      ],
      "metadata": {
        "id": "81ISFus2E6jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 훈련/검증 데이터 분리\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y,\n",
        "                                                      test_size=0.1,    # 9:1\n",
        "                                                      stratify=y,       # 타깃값 비율 일정하게\n",
        "                                                      random_state=10)"
      ],
      "metadata": {
        "id": "YSHTLNdToB53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4. Model\n"
      ],
      "metadata": {
        "id": "BDwpbveiFn07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logistic_model = LogisticRegression() # 모델 생성"
      ],
      "metadata": {
        "id": "rmWF-7pEFn_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5. Learning\n",
        "### ★ Grid Search"
      ],
      "metadata": {
        "id": "XPEeIrtQGJIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5-1. Setting"
      ],
      "metadata": {
        "id": "5gB6dvLlGJS0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iaOEqUK4GJaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5-2. Learning + ★ Grid Search"
      ],
      "metadata": {
        "id": "uMmENV_FGPBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 하이퍼파라미터 값 목록\n",
        "lr_params = {'C':[0.1, 0.125, 0.2], 'max_iter':[800, 900, 1000],\n",
        "             'solver':['liblinear'], 'random_state':[42]}\n",
        "# 그리드서치 객체 생성\n",
        "gridsearch_logistic_model = GridSearchCV(estimator=logistic_model,\n",
        "                                         param_grid=lr_params,\n",
        "                                         scoring='roc_auc', # 평가지표\n",
        "                                         cv=5)\n",
        "\n",
        "# 그리드서치 수행\n",
        "gridsearch_logistic_model.fit(X_train, y_train)  # 모델 훈련\n",
        "\n",
        "print(f\"최적 하이퍼파라미터: {gridsearch_logistic_model.best_params_}\")"
      ],
      "metadata": {
        "id": "2Z71NNIGGPKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 6. Validation"
      ],
      "metadata": {
        "id": "ddhXsgTAGPas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logistic_model.predict_proba(X_valid) # 0 또는 1 예측 확률\n",
        "# logistic_model.predict(X_valid)       # 0 또는 1 예측 결과\n",
        "\n",
        "# 검증데이터를 통한 타깃값이 1일 확률 예측\n",
        "y_valid_preds = gridsearch_logistic_model.best_estimator_.predict_proba(X_valid)[:, 1]"
      ],
      "metadata": {
        "id": "Ge7Ssxj4GPlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수\n",
        "\n",
        "# 검증 데이터 ROC ACU\n",
        "roc_auc = roc_auc_score(y_valid, y_valid_preds)\n",
        "\n",
        "print(f\"선형 회귀 RMSLE 값: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "id": "YQyneVrWHKrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TzxvoFCAZT7"
      },
      "source": [
        "# STEP 7. Prediction and Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7-1. Prediction"
      ],
      "metadata": {
        "id": "Iwjg_6nsH2gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 타깃값 1일 확률 예측\n",
        "preds = gridsearch_logistic_model.best_estimator_.predict_proba(X_test)[:, 1]"
      ],
      "metadata": {
        "id": "0Cs_Px6aH8h6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrKX3dBvF5Ib"
      },
      "source": [
        "Step 7-2. Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7NJo_4fF6U-"
      },
      "outputs": [],
      "source": [
        "submission['target'] = preds\n",
        "submission.to_csv('submission.csv', index=False)   # 제출 파일 생성"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}