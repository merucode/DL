{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/01-colab-study_must_have_pytorch/09-%5Bimage-color%5D-let-there-be-color.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 0. Version check and Install Dependency"
      ],
      "metadata": {
        "id": "LxkMBWDW9T3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0-1. Version Check"
      ],
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ],
      "metadata": {
        "id": "pvZ7Lm3Apv1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0-2. Install Dependency"
      ],
      "metadata": {
        "id": "cNpk3WdHys1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle opencv-python"
      ],
      "metadata": {
        "id": "mUI6DpQ_vP6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 1. Check Data"
      ],
      "metadata": {
        "id": "TquybxQaqfE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-1. Load data"
      ],
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export export KAGGLE_USERNAME=merucode && export KAGGLE_KEY=bdcbea5659e552b761539150bd91ba62 && kaggle datasets download -d adityajn105/flickr8k"
      ],
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip flickr8k.zip"
      ],
      "metadata": {
        "id": "-hdhetJwvt9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1-2. Check data type"
      ],
      "metadata": {
        "id": "yLz34AIjzFI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "# 데이터셋에 포함된 파일명을 불러옴\n",
        "imgs = glob.glob(\"/content/Images/*.jpg\")\n",
        "print(imgs)\n",
        "\n",
        "# 이미지 9개를 표기\n",
        "for i in range(9):\n",
        "   img = Image.open(imgs[i])\n",
        "   plt.subplot(3, 3, i+1)\n",
        "   plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BIwItmZr48ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 2. Dataset"
      ],
      "metadata": {
        "id": "dHoQK0Vw5UWP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-1. Data Preprocessing"
      ],
      "metadata": {
        "id": "y06FvZ9vxunU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# RGB를 LAB으로 변환\n",
        "def rgb2lab(rgb):\n",
        "   return cv2.cvtColor(rgb, cv2.COLOR_RGB2LAB)\n",
        "\n",
        "# LAB를 RGB로 변환합니다\n",
        "def lab2rgb(lab):\n",
        "   return cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)"
      ],
      "metadata": {
        "id": "fnmFuKNwx279"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-2. Dataset"
      ],
      "metadata": {
        "id": "O5R-dOyQxufe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "# 학습에 이용할 데이터셋 객체\n",
        "class AutoColoring(Dataset):\n",
        "   def __init__(self):  # ❶ 데이터셋의 초기화 함수\n",
        "       self.data = glob.glob(\"/content/Images/*.jpg\")\n",
        "\n",
        "   def __len__(self):   # ❷ 사용 가능한 데이터의 개수를 반환하는 함수\n",
        "       return len(self.data)\n",
        "\n",
        "   def __getitem__(self, i): # ❸ 데이터를 호출하는 함수\n",
        "       # RGB 이미지를 불러옴\n",
        "       rgb = np.array(Image.open(self.data[i]).resize((256, 256)))\n",
        "       # LAB로 변환\n",
        "       lab = rgb2lab(rgb)\n",
        "\n",
        "       # 파이토치는 채널이 가장 앞에 와야 하므로 transpose\n",
        "       lab = lab.transpose((2, 0, 1)).astype(np.float32)\n",
        "\n",
        "       return lab[0], lab[1:]"
      ],
      "metadata": {
        "id": "i1PriHOMx3Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2-3. Dataloader"
      ],
      "metadata": {
        "id": "p_-eif0RxuQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "dataset = AutoColoring()\n",
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "B4jMESbH5T7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3. Module"
      ],
      "metadata": {
        "id": "UPv6ybM8zJYk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-1. Low Level"
      ],
      "metadata": {
        "id": "QQnNmDIS5iyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LowLevel(nn.Module):\n",
        "   def __init__(self):\n",
        "       # 로 레벨 특징 추출기를 구성하는 층의 정의\n",
        "       super(LowLevel, self).__init__()\n",
        "\n",
        "       self.low1 = nn.Conv2d(1, 64,\n",
        "                             kernel_size=3, stride=2, padding=1)\n",
        "       self.lb1 = nn.BatchNorm2d(64)\n",
        "       self.low2 = nn.Conv2d(64, 128,\n",
        "                             kernel_size=3, stride=1, padding=1)\n",
        "       self.lb2 = nn.BatchNorm2d(128)\n",
        "       self.low3 = nn.Conv2d(128, 128,\n",
        "                             kernel_size=3, stride=2, padding=1)\n",
        "       self.lb3 = nn.BatchNorm2d(128)\n",
        "       self.low4 = nn.Conv2d(128, 256,\n",
        "                             kernel_size=3, stride=1, padding=1)\n",
        "       self.lb4 = nn.BatchNorm2d(256)\n",
        "       self.low5 = nn.Conv2d(256, 256,\n",
        "                             kernel_size=3, stride=2, padding=1)\n",
        "       self.lb5 = nn.BatchNorm2d(256)\n",
        "       self.low6 = nn.Conv2d(256, 512,\n",
        "                             kernel_size=3, stride=1, padding=1)\n",
        "       self.lb6 = nn.BatchNorm2d(512)\n",
        "\n",
        "       self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "   def forward(self, x):\n",
        "       # 기본 블록 구성\n",
        "       low = self.low1(x)        #  ❶합성곱\n",
        "       low = self.lb1(low)       #  ❷배치 정규화\n",
        "       low = self.sigmoid(low)   #  ❸시그모이드\n",
        "\n",
        "       low = self.low2(low)\n",
        "       low = self.lb2(low)\n",
        "       low = self.sigmoid(low)\n",
        "\n",
        "       low = self.low3(low)\n",
        "       low = self.lb3(low)\n",
        "       low = self.sigmoid(low)\n",
        "\n",
        "       low = self.low4(low)\n",
        "       low = self.lb4(low)\n",
        "       low = self.sigmoid(low)\n",
        "\n",
        "       low = self.low5(low)\n",
        "       low = self.lb5(low)\n",
        "       low = self.sigmoid(low)\n",
        "\n",
        "       low = self.low6(low)\n",
        "       low = self.lb6(low)\n",
        "       low = self.sigmoid(low)\n",
        "\n",
        "       return low"
      ],
      "metadata": {
        "id": "8D-KUCcNyiP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-2. Middle Level"
      ],
      "metadata": {
        "id": "HdgxJhPFyixh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MidLevel(nn.Module):\n",
        "   def __init__(self):\n",
        "       # 미들 레벨 특징 추출기를 구성하는 층의 정의\n",
        "       super(MidLevel, self).__init__()\n",
        "\n",
        "       self.mid1 = nn.Conv2d(512, 512,\n",
        "                             kernel_size=3, stride=1, padding=1)\n",
        "       self.mb1 = nn.BatchNorm2d(512)\n",
        "       self.mid2 = nn.Conv2d(512, 256,\n",
        "                             kernel_size=3, stride=1, padding=1)\n",
        "       self.mb2 = nn.BatchNorm2d(256)\n",
        "\n",
        "       self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "   def forward(self, x):\n",
        "       # 미들 레벨 특징 추출기의 기본 블록\n",
        "       mid = self.mid1(x)       #  ❶합성곱\n",
        "       mid = self.mb1(mid)      #  ❷배치 정규화\n",
        "       mid = self.sigmoid(mid)  #  ❸시그모이드\n",
        "\n",
        "       mid = self.mid2(mid)\n",
        "       mid = self.mb2(mid)\n",
        "       mid = self.sigmoid(mid)\n",
        "\n",
        "       return mid"
      ],
      "metadata": {
        "id": "zYry8SdYyi6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-3. Global Level"
      ],
      "metadata": {
        "id": "Pu7yAl6dyjBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GlobalLevel(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(GlobalLevel, self).__init__()\n",
        "\n",
        "       self.glob1 = nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1)\n",
        "       self.gb1 = nn.BatchNorm2d(512)\n",
        "       self.glob2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "       self.gb2 = nn.BatchNorm2d(512)\n",
        "       self.glob3 = nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1)\n",
        "       self.gb3 = nn.BatchNorm2d(512)\n",
        "       self.glob4 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "       self.gb4 = nn.BatchNorm2d(512)\n",
        "\n",
        "       # 글로벌 레벨 특징 추출기의 MLP층 구성\n",
        "       # 여기서는 분류기로 사용되는것이 아닌,\n",
        "       # 색을 칠하기 위해 사용하는 특징으로 사용\n",
        "       self.fc1 = nn.Linear(in_features=32768, out_features=1024)\n",
        "       self.fc2 = nn.Linear(in_features=1024, out_features=512)\n",
        "       self.fc3 = nn.Linear(in_features=512, out_features=256)\n",
        "\n",
        "       self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "   def forward(self, x):\n",
        "       # 글로벌 레벨 특징 추출기의 기본 블록\n",
        "       glo = self.glob1(x)         # 합성곱\n",
        "       glo = self.gb1(glo)         # 배치 정규화\n",
        "       glo = self.sigmoid(glo)     # 활성화\n",
        "\n",
        "       glo = self.glob2(glo)\n",
        "       glo = self.gb2(glo)\n",
        "       glo = self.sigmoid(glo)\n",
        "\n",
        "       glo = self.glob3(glo)\n",
        "       glo = self.gb3(glo)\n",
        "       glo = self.sigmoid(glo)\n",
        "\n",
        "       glo = self.glob4(glo)\n",
        "       glo = self.gb4(glo)\n",
        "       glo = self.sigmoid(glo)\n",
        "\n",
        "       # 추출된 특징을 1차원으로 펼쳐준다\n",
        "       glo = torch.flatten(glo, start_dim=1)\n",
        "       glo = self.fc1(glo)\n",
        "       glo = self.sigmoid(glo)\n",
        "       glo = self.fc2(glo)\n",
        "       glo = self.sigmoid(glo)\n",
        "       glo = self.fc3(glo)\n",
        "       glo = self.sigmoid(glo)\n",
        "\n",
        "       return glo"
      ],
      "metadata": {
        "id": "EoPCs-bbzhS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-4. 컬러라이제이션 네크워크"
      ],
      "metadata": {
        "id": "idO4r5z-zhnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Colorization(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(Colorization, self).__init__()\n",
        "       # Colorization 네트워크 구성에 필요한 층의 정의\n",
        "\n",
        "       # ❶업샘플링 커널:3 스트라이드:1 패딩:1\n",
        "       self.color1 = nn.ConvTranspose2d(256, 128, 3, 1, 1)\n",
        "       self.cb1 = nn.BatchNorm2d(128)\n",
        "\n",
        "       # ❷업샘플링 커널:2 스트라이드:2 패딩:0\n",
        "       self.color2 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
        "       self.cb2 = nn.BatchNorm2d(64)\n",
        "\n",
        "       self.color3 = nn.ConvTranspose2d(64, 64, 3, 1, 1)\n",
        "       self.cb3 = nn.BatchNorm2d(64)\n",
        "       self.color4 = nn.ConvTranspose2d(64, 32, 2, 2)\n",
        "       self.cb4 = nn.BatchNorm2d(32)\n",
        "       self.color5 = nn.ConvTranspose2d(32, 2, 2, 2)\n",
        "\n",
        "       self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "   def forward(self, x):\n",
        "       color = self.color1(x)\n",
        "       color = self.cb1(color)\n",
        "       color = self.sigmoid(color)\n",
        "       color = self.color2(color)\n",
        "       color = self.cb2(color)\n",
        "       color = self.sigmoid(color)\n",
        "       color = self.color3(color)\n",
        "       color = self.cb3(color)\n",
        "       color = self.sigmoid(color)\n",
        "       color = self.color4(color)\n",
        "       color = self.cb4(color)\n",
        "       color = self.sigmoid(color)\n",
        "       color = self.color5(color)\n",
        "\n",
        "       return color"
      ],
      "metadata": {
        "id": "uJjWmuTmz3Hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3-5. 자동채색 모델"
      ],
      "metadata": {
        "id": "pJ7PP7t40HqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoColoringModel(nn.Module):\n",
        "   def __init__(self):\n",
        "       super(AutoColoringModel, self).__init__()\n",
        "       # 로 레벨 특징 추출기\n",
        "       self.low = LowLevel()\n",
        "       # 미들 레벨  특징 추출기\n",
        "       self.mid = MidLevel()\n",
        "       # 글로벌 레벨 특징 추출기\n",
        "       self.glob = GlobalLevel()\n",
        "       # 특징 합치기\n",
        "       self.fusion = nn.Conv2d(512, 256,  kernel_size=3, stride=1, padding=1)\n",
        "       # 색 입히기\n",
        "       self.color = Colorization()\n",
        "       # 활성화 함수\n",
        "       self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "   def forward(self, x):\n",
        "       # ❶로 레벨 특징 추출기로 입력\n",
        "       low = self.low(x)\n",
        "\n",
        "       # 로 레벨 특징 추출기의 출력을 넣어줌\n",
        "       mid = self.mid(low)\n",
        "       glo = self.glob(low)\n",
        "\n",
        "       # ❷글로벌 레벨 특징 추출기의 출력을 미들 레벨 특징 추출기의\n",
        "       # 출력 크기가 되도록 반복\n",
        "       fusion = glo.repeat(1, mid.shape[2]*mid.shape[2])\n",
        "       fusion = torch.reshape(fusion, (-1, 256, mid.shape[2], mid.shape[2]))\n",
        "\n",
        "       # ❸글로벌 레벨 특징 추출기의 특징과 미들 레벨 특징 추출기의 특징을 결합\n",
        "       fusion = torch.cat([mid, fusion], dim=1)\n",
        "       fusion = self.fusion(fusion)\n",
        "       fusion = self.sigmoid(fusion)\n",
        "\n",
        "       # ❹컬러라이제이션 네크워크\n",
        "       color = self.color(fusion)\n",
        "\n",
        "       return color"
      ],
      "metadata": {
        "id": "IiCn61Vk0K5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 4. Learning"
      ],
      "metadata": {
        "id": "Qa9kBj02zz7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-1. Setting"
      ],
      "metadata": {
        "id": "cg8ZCYcJ0JIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "from torch.optim.adam import Adam\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = AutoColoringModel().to(device)\n",
        "\n",
        "optim = Adam(params=model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "B8clGgz65sxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-2. Learning"
      ],
      "metadata": {
        "id": "lH9EvJSJz-AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 루프 정의\n",
        "#for epoch in range(200):\n",
        "for epoch in range(20):\n",
        "   iterator = tqdm.tqdm(loader)\n",
        "   for L, AB in iterator:\n",
        "       # ➋L 채널은 흑백 이미지 이므로 채널 차원을 확보해야 함\n",
        "       L = torch.unsqueeze(L, dim=1).to(device)\n",
        "       optim.zero_grad()\n",
        "\n",
        "       # ➌ A, B 채널을 예측\n",
        "       pred = model(L)\n",
        "\n",
        "       # ➍손실 계산과 오차 역전파\n",
        "       loss = nn.MSELoss()(pred, AB.to(device))\n",
        "       loss.backward()\n",
        "       optim.step()\n",
        "\n",
        "       iterator.set_description(f\"epoch:{epoch} loss:{loss.item()}\")\n",
        "\n",
        "# ➎모델 가중치 저장\n",
        "torch.save(model.state_dict(), \"AutoColor.pth\")"
      ],
      "metadata": {
        "id": "krz6kIYz52wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 5. Evaluation"
      ],
      "metadata": {
        "id": "sdk0NFRA085c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ➊결과 비교를 위한 실제 이미지\n",
        "# pyplot의 이미지 형식에 맞추기 위한 약간의 변형이 필요함\n",
        "test_L, test_AB = dataset[0]\n",
        "test_L = np.expand_dims(test_L, axis=0)\n",
        "real_img = np.concatenate([test_L, test_AB])\n",
        "real_img = real_img.transpose(1, 2, 0).astype(np.uint8)\n",
        "real_img = lab2rgb(real_img)\n",
        "\n",
        "# 모델이 예측한 결과\n",
        "with torch.no_grad():\n",
        "   # 모델 가중치 불러오기\n",
        "   model.load_state_dict(\n",
        "       torch.load(\"AutoColor.pth\", map_location=device))\n",
        "\n",
        "   # ➋모델의 예측값 계산\n",
        "   input_tensor = torch.tensor(test_L)\n",
        "   input_tensor = torch.unsqueeze(input_tensor, dim=0).to(device)\n",
        "   pred_AB = model(input_tensor)\n",
        "\n",
        "   # ➌pyplot의 이미지 형식에 맞추기 위한 약간의 변형이 필요함\n",
        "   pred_LAB = torch.cat([input_tensor, pred_AB], dim=1)\n",
        "   pred_LAB = torch.squeeze(pred_LAB)\n",
        "   pred_LAB = pred_LAB.permute(1, 2, 0).cpu().numpy()\n",
        "   pred_LAB = lab2rgb(pred_LAB.astype(np.uint8))\n",
        "\n",
        "# ➍실제와 예측값의 비교\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(real_img)\n",
        "plt.title(\"real image\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(pred_LAB)\n",
        "plt.title(\"predicted image\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6t5jawBx8ibI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBXT9XvEEr_Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}