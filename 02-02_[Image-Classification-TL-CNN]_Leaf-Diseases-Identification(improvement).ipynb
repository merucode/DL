{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/81-colab-keggle_image/02-02_%5BImage-Classification-TL-CNN%5D_Leaf-Diseases-Identification(improvement).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZmla44eMnQC"
      },
      "source": [
        "# Imformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_8PiW9AMqQh"
      },
      "source": [
        "* Title : [Leaf Diseases Identification](https://www.kaggle.com/c/plant-pathology-2020-fgvc7)\n",
        "* Type : Image classification\n",
        "* Evaluation : ROE ACU\n",
        "* Model : CNN(transfer learning)\n",
        "* Python version: 3.10.6\n",
        "* Basic library version\n",
        "  * torch(torch==2.0.1+cu118)\n",
        "  * torchvision(torchvision==0.15.2+cu118)\n",
        "  * sklearn(scikit-learn==1.2.2)\n",
        "  * cv2(opencv-python==4.7.0.72)\n",
        "  * albumentations(albumentations==1.2.1): 이미지 변환기\n",
        "  * numpy(numpy==1.22.4)\n",
        "  * pandas(pandas==1.5.3)\n",
        "  * matplotlib(matplotlib==3.7.1)\n",
        "  * zipfile, random, math, shutil, os.\n",
        "* Addtional Library version\n",
        "  * transformers(transformers==4.31.0): 스케줄러 사용을 위해\n",
        "  * efficientnet_python(efficientnet-python==0.7.1): 사전 학습 모델\n",
        "* Improvement\n",
        "  * (Learning) Scheduler, More epochs\n",
        "  * (Pred) TTA(테스트 단계 데이터 증강)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxkMBWDW9T3P"
      },
      "source": [
        "# STEP 0. Version check and Install Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfgM8S72TidO"
      },
      "source": [
        "Step 0-1. Install Dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-niTKAk-M54m"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install efficientnet-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      },
      "source": [
        "Step 0-2. Version Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pvZ7Lm3Apv1B"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9v0TRhv5TudL"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOF78xJ1T2lL"
      },
      "source": [
        "Step 0-3. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9m2Gh7jjT5QL"
      },
      "outputs": [],
      "source": [
        "!export KAGGLE_USERNAME=*** && export KAGGLE_KEY=*** && kaggle competitions download -c plant-pathology-2020-fgvc7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O8C7SzT7UlEu"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "with ZipFile(data_path + 'plant-pathology-2020-fgvc7.zip') as zipper:\n",
        "  zipper.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TquybxQaqfE5"
      },
      "source": [
        "# STEP 1. Check Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      },
      "source": [
        "Step 1-1. Check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "train = pd.read_csv(data_path + 'train.csv')\n",
        "test = pd.read_csv(data_path + 'test.csv')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERzuAmCnV6sW"
      },
      "outputs": [],
      "source": [
        "train.shape, test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(3)"
      ],
      "metadata": {
        "id": "aYtlO0uVqeNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(3)"
      ],
      "metadata": {
        "id": "odtLqHYPqh71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE8h1MdeWEKQ"
      },
      "outputs": [],
      "source": [
        "submission.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLz34AIjzFI_"
      },
      "source": [
        "Step 1-2. Data Visualize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 타깃값 별로 추출\n",
        "healthy = train.loc[train['healthy']==1]\n",
        "multiple_diseases = train.loc[train['multiple_diseases']==1]\n",
        "rust = train.loc[train['rust']==1]\n",
        "scab = train.loc[train['scab']==1]"
      ],
      "metadata": {
        "id": "XfjYv7Oqqqre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A5ybi6s9V5-6"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "mpl.rc('font', size=15)\n",
        "plt.figure(figsize=(7, 7))\n",
        "\n",
        "label = ['healthy', 'multiple diseases', 'rust', 'scab']  # 타깃값 레이블\n",
        "# 타깃값 분포 파이 그래프\n",
        "plt.pie([len(healthy), len(multiple_diseases), len(rust), len(scab)],\n",
        "        labels = label,\n",
        "        autopct='%.1f%%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RknwhV_yzNcJ"
      },
      "source": [
        "Step 1-3. Data Image Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iemQGYizTJI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "import cv2 # OpenCV 라이브러리\n",
        "\n",
        "def show_images(img_ids, rows=2, cols=3):\n",
        "  assert len(img_ids) <= rows * cols # 이미지가 행/열 개수보다 많으면 오류 발생\n",
        "\n",
        "  plt.figure(figsize=(15, 8)) # 전체 Figure 크기 설정\n",
        "  grid = gridspec.GridSpec(rows, cols) # 서브플롯 배치\n",
        "\n",
        "  # 이미지 출력\n",
        "  for idx, img_id in enumerate(img_ids):\n",
        "    img_path = f'{data_path}/images/{img_id}.jpg'       # 이미지 파일 경로\n",
        "    image = cv2.imread(img_path)                        # 이미지 파일 읽기\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)      # 이미지 색상 보정\n",
        "    ax = plt.subplot(grid[idx])\n",
        "    ax.imshow(image)                                # 이미지 출력"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 타깃값별 image_id(마지막 6개)\n",
        "num_of_imgs = 6\n",
        "last_healthy_img_ids = healthy['image_id'][-num_of_imgs:]\n",
        "last_multiple_diseases_img_ids = multiple_diseases['image_id'][-num_of_imgs:]\n",
        "last_rust_img_ids = rust['image_id'][-num_of_imgs:]\n",
        "last_scab_img_ids = scab['image_id'][-num_of_imgs:]"
      ],
      "metadata": {
        "id": "3L8BuLPhtbFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(last_healthy_img_ids)"
      ],
      "metadata": {
        "id": "XMXE5K5-t3tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(last_multiple_diseases_img_ids)"
      ],
      "metadata": {
        "id": "bvjbO-Lrt-re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(last_rust_img_ids)"
      ],
      "metadata": {
        "id": "4zjwPjmEuEnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(last_scab_img_ids)"
      ],
      "metadata": {
        "id": "jfJZbpzBuEy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwqEIVGS1rtU"
      },
      "source": [
        "# STEP 2. Setting for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9H9zmkC11uZ"
      },
      "source": [
        "Step 2-1. Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flGdAWM811ct"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 시드값 고정\n",
        "seed = 50\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)                 # 파이썬 난수 생석이 시드 고정\n",
        "np.random.seed(seed)              # 넘파이 난수 생성기 시드 고정\n",
        "torch.manual_seed(seed)           # 파이토치 난수 생성기 시드 고정(CPU 사용시)\n",
        "torch.cuda.manual_seed(seed)      # 파이토치 난수 생성기 시드 고정(GPU 사용시)\n",
        "torch.cuda.manual_seed_all(seed)  # 파이토치 난수 생성기 시드 고정(멀티 GPU 사용 시)\n",
        "torch.backends.cudnn.deterministic = True # 확정적 연산 사용\n",
        "torch.backends.cudnn.benchmark = False    # 벤치마크 기능 해제\n",
        "torch.backends.cudnn.enabled = False      # cudnn 사용 해제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieRL-cJ-2stM"
      },
      "source": [
        "Step 2-2.GPU 장비 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCyRsU3I2wAc"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHoQK0Vw5UWP"
      },
      "source": [
        "# STEP 3. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv-BeF_h1rap"
      },
      "source": [
        "Step 3-1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4jMESbH5T7X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "train = pd.read_csv(data_path + 'train.csv')\n",
        "test = pd.read_csv(data_path + 'test.csv')\n",
        "submission = pd.read_csv(data_path + 'sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEhlK9uz3SVF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 훈련 데이터, 검증 데이터 세트 분리\n",
        "train, valid = train_test_split(train,\n",
        "                                test_size=0.1,                 # 9:1 비율로 test 세트 생성\n",
        "                                stratify=train[['healthy', 'multiple_diseases', 'rust', 'scab']], # 훈련 데이터, 검증 데이터 티깃값 비율 유지\n",
        "                                random_state=50)\n",
        "\n",
        "print(f\"훈련 데이터 개수: {len(train)}\")\n",
        "print(f\"검증 데이터 개수: {len(valid)}\")\n",
        "train.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OR2BLnm3IKM"
      },
      "source": [
        "Step 3-2. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFTWbgSa1p7Z"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "  # 초기화 메서드(생성자)\n",
        "  def __init__(self, df, img_dir='./', transform=None, is_test=False):\n",
        "    super().__init__() # 상송받은 Dataset 생성자 호출\n",
        "    # 전달받은 인수들 저장\n",
        "    self.df = df\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.is_test = is_test\n",
        "\n",
        "  # 데이터셋 크기 반환 메서드\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  # idx 해당하는 데이터 반환 메서드\n",
        "  def __getitem__(self, idx):\n",
        "    img_id = self.df.iloc[idx, 0]               # 이미지 ID\n",
        "    img_path = self.img_dir + img_id + '.jpg'   # 이미지 파일 경로\n",
        "    image = cv2.imread(img_path)                # 이미지 파일 읽기\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # 이미지 색상 보정\n",
        "\n",
        "    if self.transform is not None:  # 변화기가 있다면 이미지 변환\n",
        "      image = self.transform(image=image)['image']    # albumentations 모듈 변환기\n",
        "      # image = self.transform(image)                 # torchvision transform 모듈 변환기\n",
        "\n",
        "    # 테스트 데이터면 이미지 데이터만 반환, 그렇치 않으면 타깃값도 반환\n",
        "    if self.is_test:\n",
        "      return image          # 테스트용\n",
        "    else:\n",
        "      # 타깃값 4개 중 가장 큰 값의 인덱스\n",
        "      label = np.argmax(self.df.iloc[idx, 1:5])\n",
        "      return image, label   # 훈련/검증용"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# 훈련 데이터용 변환기\n",
        "transform_train = A.Compose([\n",
        "    A.Resize(450, 650),                                # 이미지 크기 조절\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2,   # 밝기 대비 조절\n",
        "                               contrast_limit=0.2,\n",
        "                               p=0.3),\n",
        "    A.VerticalFlip(p=0.2),                             # 상하 대칭 변환\n",
        "    A.HorizontalFlip(p=0.5),                           # 좌우 대칭 변환\n",
        "    A.ShiftScaleRotate(                                # 이동, 스케일링, 회전 변환\n",
        "        shift_limit=0.1,\n",
        "        scale_limit=0.2,\n",
        "        rotate_limit=30,\n",
        "        p=0.3),\n",
        "    A.OneOf([A.Emboss(p=1),                            # 양각화, 날카로움, 불러 효과\n",
        "             A.Sharpen(p=1),\n",
        "             A.Blur(p=1)], p=0.3),\n",
        "    A.PiecewiseAffine(p=0.3),                          # 어파인 변환\n",
        "    A.Normalize(),                                     # 정규화 변환\n",
        "    ToTensorV2()                                       # 텐서 변환\n",
        "])\n",
        "\n",
        "# 검증/테스트 데이터용 변환기\n",
        "transform_test = A.Compose([\n",
        "    A.Resize(450, 650),\n",
        "    A.Normalize(),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "metadata": {
        "id": "rXU3oEecwXDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xypihBVa54gv"
      },
      "outputs": [],
      "source": [
        "img_dir = '/content/images/'\n",
        "\n",
        "dataset_train = ImageDataset(df=train, img_dir=img_dir, transform=transform_train)\n",
        "dataset_valid = ImageDataset(df=valid, img_dir=img_dir, transform=transform_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZtaJBsW3LUJ"
      },
      "source": [
        "Step 3-3. Dataloader(multiprocess)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 멀티프로세서 사용 시 데이터 로더 시드 고정\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)"
      ],
      "metadata": {
        "id": "MLqKi_yyyiK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-lUSwZJ1qVJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader # 데이터 로더 클래스\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size,\n",
        "                          shuffle=True, worker_init_fn=seed_worker,\n",
        "                          generator=g, num_workers=2)\n",
        "loader_valid = DataLoader(dataset=dataset_valid, batch_size=batch_size,\n",
        "                          shuffle=False, worker_init_fn=seed_worker,\n",
        "                          generator=g, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPv6ybM8zJYk"
      },
      "source": [
        "# STEP 4. Module"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-1. Pretrained Model Load"
      ],
      "metadata": {
        "id": "0h6jqMqpzfvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet # EfficientNet 모듈\n",
        "\n",
        "# 사전 훈련된 'efficientnet-b7' 모델 불러오기\n",
        "model = EfficientNet.from_pretrained('efficientnet-b7', num_classes=4)  # num_classes : 최종 출력 갯수"
      ],
      "metadata": {
        "id": "oN90O7mazi9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-1. Pretrained Model Load(output number control other method)"
      ],
      "metadata": {
        "id": "LrseNA_i0Y8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet # EfficientNet 모듈\n",
        "import torch.nn as nn\n",
        "\n",
        "# 사전 훈련된 'efficientnet-b7' 모델 불러오기\n",
        "model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "\n",
        "# 사전 모델 마지막 계층 수정(출력값 갯수 수정)\n",
        "model._fc = nn.Sequential(\n",
        "    nn.Linear(model._fc.in_features, model._fc.out_features), # 2560 > 1000\n",
        "    nn.ReLU(),          # 활성화 함수\n",
        "    nn.Dropout(p=0.5),  # 50% 드롭아웃\n",
        "    nn.Linear(model._fc.out_features, 4) # 1000 > 4\n",
        ")"
      ],
      "metadata": {
        "id": "aXHpla4S0fbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa9kBj02zz7m"
      },
      "source": [
        "# STEP 5. Learning\n",
        "### ★Improvement: Scheduler + More Epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg8ZCYcJ0JIz"
      },
      "source": [
        "Step 5-1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8clGgz65sxJ"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from torch.optim.adamw import AdamW\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 옵티마이저\n",
        "optim = AdamW(model.parameters(), lr=0.00006, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH9EvJSJz-AX"
      },
      "source": [
        "Step 5-2. Learning + ★Improvement: Scheduler + More Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krz6kIYz52wm"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산\n",
        "from tqdm.notebook import tqdm             # 진행률 표시\n",
        "\n",
        "epochs = 1 # 39 # 총 에폭\n",
        "\n",
        "# ★ Scheduler\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "scheduler = get_cosine_schedule_with_warmup(optim,\n",
        "                                            num_warmup_steps=len(loader_train)*3,\n",
        "                                            num_training_steps=len(loader_train)*epochs)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  # == [훈련] ================================\n",
        "  model.train()         # 모델을 훈련 상태로 설정\n",
        "  epoch_train_loss = 0  # 에폭별 손실값 초기화(훈련 데이터용)\n",
        "\n",
        "  # 반복 횟수 만큼 반복\n",
        "  for images, labels in tqdm(loader_train):\n",
        "    # 이미지, 레이블 데이터 미니배치를 장비에 할당\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    optim.zero_grad()         # 옵티마이저 기울기 초기화\n",
        "    outputs = model(images)   # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n",
        "    loss = criterion(outputs, labels)   # 손실값 계산(예측값과 타깃값의 오차)\n",
        "    epoch_train_loss += loss.item() # 현재 배치에서의 손실 추가\n",
        "    loss.backward()           # 역전파 수행\n",
        "    optim.step()     # 가중치 갱신\n",
        "    scheduler.step()\n",
        "\n",
        "  # 훈련 데이터 손실값 출력\n",
        "  print(f\"에폭 [{epoch+1}/{epochs}] - 손실값: {epoch_train_loss/len(loader_train):.4f}\")\n",
        "\n",
        "  # == [검증] ================================\n",
        "  model.eval()          # 모델을 평가 상태로 설정\n",
        "  epoch_valid_loss = 0  # 에폭별 손실값 초기화(검증 데이터용)\n",
        "  preds_list = []       # 예측 확률값 저장용 리스트 초기화\n",
        "  true_onehot_list = [] # 실제 타깃값 저장용 리스트 초기화\n",
        "\n",
        "  with torch.no_grad(): # 기울기 계산 비활성화\n",
        "    # 미니 배치 단위로 검증\n",
        "    for images, labels in loader_valid:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)                #  순전파\n",
        "      loss = criterion(outputs, labels)      # 손실값 계산(검증 데이터용)\n",
        "      epoch_valid_loss += loss.item()\n",
        "\n",
        "      # 예측값 및 실제값 계산\n",
        "      preds = torch.softmax(outputs.cpu(), dim=1).numpy()  # 예측 확률 값\n",
        "      labels = labels.to(\"cpu\") # ERROR HANDLING: indices should be either on cpu or on the same device as the indexed tensor (cpu)\n",
        "      true_onehot = torch.eye(4)[labels].cpu().numpy()     # 실제값 (원-핫 인코딩 형식)\n",
        "      # 예측 확률값과 실제값 저장\n",
        "      preds_list.extend(preds)\n",
        "      true_onehot_list.extend(true_onehot)\n",
        "\n",
        "  # 검증 데이터 손실값 및 ROC AUC 점수 출력\n",
        "  print(f\"에폭 [{epoch+1}/{epochs}] - 검증 데이터 손실값: {epoch_valid_loss/len(loader_valid):.4f} / \\\n",
        "  검증 데이터 ROC AUC: {roc_auc_score(true_onehot_list, preds_list):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdk0NFRA085c"
      },
      "source": [
        "# STEP 6. Validation(STEP 5 동시 진행)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJpeWQqqAbyq"
      },
      "source": [
        "Step 6-1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t5jawBx8ibI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWZzeX2QAadF"
      },
      "source": [
        "Step 6-2. Model Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FP5Qr7CAaX1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TzxvoFCAZT7"
      },
      "source": [
        "# STEP 7. Evaluation and Submission\n",
        "### ★Improvement: TTA(테스트 단계 데이터 증강)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4NkzUqjFMv0"
      },
      "source": [
        "Step 7-1. Setting + ★Improvement: TTA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs7stCVDFKcY"
      },
      "outputs": [],
      "source": [
        "dataset_test = ImageDataset(df=submission, img_dir=img_dir,\n",
        "                            transform=transform_test, is_test=True)\n",
        "loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size,\n",
        "                         shuffle=False, worker_init_fn=seed_worker,\n",
        "                         generator=g, num_workers=2)\n",
        "\n",
        "# ★ TTA용 데이터 셋 및 데이터 로더\n",
        "dataset_TTA = ImageDataset(df=submission, img_dir=img_dir,\n",
        "                            transform=transform_train, is_test=True)\n",
        "loader_TTA = DataLoader(dataset=dataset_test, batch_size=batch_size,\n",
        "                         shuffle=False, worker_init_fn=seed_worker,\n",
        "                         generator=g, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K8oHdB4FZZU"
      },
      "source": [
        "Step 7-2. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4RI5dL7FOQL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "model.eval()  # 모델 평가 상태로 설정\n",
        "\n",
        "# 원본 데이터로 예측\n",
        "preds_test = np.zeros((len(test), 4)) # 예측값 저장용 배열 초기화\n",
        "\n",
        "with torch.no_grad(): # 기울기 계산 비활성화\n",
        "  for i, images in enumerate(loader_test):\n",
        "    # 이미지 데이터 미니배치를 장비에 할당\n",
        "    images = images.to(device)\n",
        "\n",
        "    # 순전파\n",
        "    outputs = model(images)\n",
        "    # 타깃값 예측 확률\n",
        "    preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n",
        "    # preds에 preds_part 이어 붙이기\n",
        "    preds_test[i*batch_size:(i+1)*batch_size] += preds_part"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_test = submission.copy() # 제출 샘플 파일 복사\n",
        "submission_test[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_test   # submission df 결과값 재설정"
      ],
      "metadata": {
        "id": "NPi5e_3vURqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7-3.★TTA"
      ],
      "metadata": {
        "id": "fWxs2AN6N6DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_TTA = 7\n",
        "\n",
        "# TTA 데이터로 예측\n",
        "preds_tta = np.zeros((len(test), 4)) # 예측값 저장용 배열 초기화(TTA)\n",
        "\n",
        "# TTA 적용 예측\n",
        "for i in range(num_TTA):\n",
        "  with torch.no_grad(): # 기울기 계산 비활성화\n",
        "    for i, images in enumerate(loader_test):\n",
        "      # 이미지 데이터 미니배치를 장비에 할당\n",
        "      images = images.to(device)\n",
        "\n",
        "      # 순전파\n",
        "      outputs = model(images)\n",
        "      # 타깃값 예측 확률\n",
        "      preds_part = torch.softmax(outputs.cpu(), dim=1).squeeze().numpy()\n",
        "      # preds에 preds_part 이어 붙이기\n",
        "      preds_tta[i*batch_size:(i+1)*batch_size] += preds_part\n",
        "\n",
        "preds_tta /= num_TTA # 누적값의 평균"
      ],
      "metadata": {
        "id": "5-AG8XgCOCaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_tta = submission.copy() # 제출 샘플 파일 복사\n",
        "submission_tta[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds_tta   # submission df 결과값 재설정"
      ],
      "metadata": {
        "id": "CWYTqCrMT7D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7-4. ★Label Smoothing"
      ],
      "metadata": {
        "id": "kNaMaowrUGXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_label_smoothiing(df, target, alpha, threshold):\n",
        "  df_target = df[target].copy() # 타깃값 복사\n",
        "  k = len(target)               # 타깃값 개수\n",
        "\n",
        "  for idx, row in df_target.iterrows(): #\n",
        "    if (row > threshold).any():         # 각 타깃값에 대해 임계값 넘는지 확인(임계값 넘으면 과잉 확신)\n",
        "      row = (1 - alpha)*row + alpha/k   # 레이블 스무딩 적용\n",
        "      df_target.iloc[idx] = row\n",
        "  return df_target"
      ],
      "metadata": {
        "id": "eF7dIZOnUbp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.001     # 레이블 스무딩 강도\n",
        "threshold = 0.999 # 레이블 스무딩을 적용할 임계값\n",
        "\n",
        "# 레이블 스무딩을 위해 df 복사\n",
        "submission_test_ls = submission_test.copy()\n",
        "submission_tta_ls = submission_tta.copy()\n",
        "\n",
        "target = ['healthy', 'multiple_diseases', 'rust', 'scab'] # 타깃값 열 이름\n",
        "\n",
        "# 레이블 스무딩 적용\n",
        "submission_test_ls[target] = apply_label_smoothiing(submission_test_ls, target,\n",
        "                                                    alpha, threshold)\n",
        "submission_tta_ls[target] = apply_label_smoothiing(submission_tta_ls, target,\n",
        "                                                    alpha, threshold)"
      ],
      "metadata": {
        "id": "jKwta5XpYMau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7-5.Submission"
      ],
      "metadata": {
        "id": "XNlqQAqlUKRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_test.to_csv('submission_test.csv', index=False)      # 제출 파일 생성\n",
        "submission_tta.to_csv('submission_tta.csv', index=False)        # 제출 파일 생성\n",
        "submission_test_ls.to_csv('submission_test_ls.csv', index=False)        # 제출 파일 생성\n",
        "submission_tta_ls.to_csv('submission_tta_ls.csv', index=False)        # 제출 파일 생성"
      ],
      "metadata": {
        "id": "spPQGqSJUHRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}