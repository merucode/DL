{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/merucode/DL/blob/81-colab-keggle_image/03-02_%5BImage-Classification-TL-CNN%5D_Chest-Xray-Pneumonia(improvement).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZmla44eMnQC"
      },
      "source": [
        "# Imformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_8PiW9AMqQh"
      },
      "source": [
        "* Title : [Chest X-Ray Penumonia](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)\n",
        "* Type : Image Binary classification\n",
        "* Evaluation : Accuracy, Recall, F1\n",
        "* Model : CNN(Transfer learning)\n",
        "* Python version: 3.10.6\n",
        "* Basic library version\n",
        "  * torch(torch==2.0.1+cu118)\n",
        "  * torchvision(torchvision==0.15.2+cu118)\n",
        "  * sklearn(scikit-learn==1.2.2)\n",
        "  * cv2(opencv-python==4.7.0.72)\n",
        "  * numpy(numpy==1.22.4)\n",
        "  * pandas(pandas==1.5.3)\n",
        "  * matplotlib(matplotlib==3.7.1)\n",
        "  * zipfile, random, math, shutil, os.\n",
        "* Addtional Library version\n",
        "  * transformers(transformers==4.31.0)\n",
        "  * efficientnet_python(efficientnet-python==0.7.1): 사전 학습 모델\n",
        "* Considering Library version\n",
        "  * albumentations(albumentations==1.2.1): 이미지 변환기\n",
        "* Improvement\n",
        "  * (Learning) Optimizer, Scheduler\n",
        "  * Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxkMBWDW9T3P"
      },
      "source": [
        "# STEP 0. Version check and Install Dependency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfgM8S72TidO"
      },
      "source": [
        "Step 0-1. Install Dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-niTKAk-M54m"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install efficientnet-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fg2WcTOqf5A"
      },
      "source": [
        "Step 0-2. Version Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pvZ7Lm3Apv1B"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(f\"Python version:{sys.version}\")                  # python\n",
        "print(\"Torch version:{}\".format(torch.__version__))     # torch\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))    # cuda\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))    # cudnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9v0TRhv5TudL"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOF78xJ1T2lL"
      },
      "source": [
        "Step 0-3. Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9m2Gh7jjT5QL"
      },
      "outputs": [],
      "source": [
        "!export KAGGLE_USERNAME=*** && export KAGGLE_KEY=*** && kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "O8C7SzT7UlEu"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "data_path = '/content/'\n",
        "\n",
        "with ZipFile(data_path + 'chest-xray-pneumonia.zip') as zipper:\n",
        "  zipper.extractall()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TquybxQaqfE5"
      },
      "source": [
        "# STEP 1. Check Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiEgwO4nzBQ4"
      },
      "source": [
        "Step 1-1. Check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_1DAWvLxNST"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "data_path = '/content/chest_xray/'\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터 경로 설정\n",
        "train_path = data_path + 'train/'\n",
        "valid_path = data_path + 'val/'\n",
        "test_path = data_path + 'test/'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "print(f\"훈련 데이터 개수: {len(glob(train_path + '*/*'))}\")\n",
        "print(f\"검증 데이터 개수: {len(glob(valid_path + '*/*'))}\")\n",
        "print(f\"테스트 데이터 개수: {len(glob(test_path + '*/*'))}\")"
      ],
      "metadata": {
        "id": "M0XboTm6JNXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_normal_imgs = []    # 모든 정상 이미지를 담을 리스트 초기화\n",
        "all_pneumonia_imgs = [] # 모든 폐렴 이미지를 담을 리스트 초기화\n",
        "\n",
        "for cat in ['train/', 'val/', 'test/']:\n",
        "  data_cat_path = data_path + cat\n",
        "  # 정상, 폐렴 이미지 경로\n",
        "  normal_imgs = glob(data_cat_path + 'NORMAL/*')\n",
        "  pneumonia_imgs = glob(data_cat_path + 'PNEUMONIA/*')\n",
        "  # 정상, 폐렴 이미지 경로를 리스트에 추가\n",
        "  all_normal_imgs.extend(normal_imgs)\n",
        "  all_pneumonia_imgs.extend(pneumonia_imgs)\n",
        "\n",
        "print(f\"정상 흉부 이미지 개수: {len(all_normal_imgs)}\")\n",
        "print(f\"폐렴 흉부 이미지 개수: {len(all_pneumonia_imgs)}\")"
      ],
      "metadata": {
        "id": "xg-Dczi1JqLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLz34AIjzFI_"
      },
      "source": [
        "Step 1-2. Data Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "A5ybi6s9V5-6"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "mpl.rc('font', size=15)\n",
        "plt.figure(figsize=(7, 7))\n",
        "\n",
        "label = ['Normal', 'Pneumonia']  # 타깃값 레이블\n",
        "# 타깃값 분포 파이 그래프\n",
        "plt.pie([len(all_normal_imgs), len(all_pneumonia_imgs)],\n",
        "        labels = label,\n",
        "        autopct='%.1f%%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RknwhV_yzNcJ"
      },
      "source": [
        "Step 1-3. Data Image Visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iemQGYizTJI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "import cv2 # OpenCV 라이브러리\n",
        "\n",
        "def show_images(img_paths, rows=2, cols=3):\n",
        "  assert len(img_paths) <= rows * cols # 이미지가 행/열 개수보다 많으면 오류 발생\n",
        "\n",
        "  plt.figure(figsize=(15, 8)) # 전체 Figure 크기 설정\n",
        "  grid = gridspec.GridSpec(rows, cols) # 서브플롯 배치\n",
        "\n",
        "  # 이미지 출력\n",
        "  for idx, img_path in enumerate(img_paths):\n",
        "    image = cv2.imread(img_path)                    # 이미지 파일 읽기\n",
        "    ax = plt.subplot(grid[idx])\n",
        "    ax.imshow(image)                                # 이미지 출력"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 타깃값별 image_paths(마지막 6개)\n",
        "num_of_imgs = 6\n",
        "normal_img_paths = all_normal_imgs[-num_of_imgs:]\n",
        "pneumonia_img_paths = all_pneumonia_imgs[-num_of_imgs:]"
      ],
      "metadata": {
        "id": "3L8BuLPhtbFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(normal_img_paths)"
      ],
      "metadata": {
        "id": "XMXE5K5-t3tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(pneumonia_img_paths)"
      ],
      "metadata": {
        "id": "bvjbO-Lrt-re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwqEIVGS1rtU"
      },
      "source": [
        "# STEP 2. Setting for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9H9zmkC11uZ"
      },
      "source": [
        "Step 2-1. Seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flGdAWM811ct"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 시드값 고정\n",
        "seed = 50\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "random.seed(seed)                 # 파이썬 난수 생석이 시드 고정\n",
        "np.random.seed(seed)              # 넘파이 난수 생성기 시드 고정\n",
        "torch.manual_seed(seed)           # 파이토치 난수 생성기 시드 고정(CPU 사용시)\n",
        "torch.cuda.manual_seed(seed)      # 파이토치 난수 생성기 시드 고정(GPU 사용시)\n",
        "torch.cuda.manual_seed_all(seed)  # 파이토치 난수 생성기 시드 고정(멀티 GPU 사용 시)\n",
        "torch.backends.cudnn.deterministic = True # 확정적 연산 사용\n",
        "torch.backends.cudnn.benchmark = False    # 벤치마크 기능 해제\n",
        "torch.backends.cudnn.enabled = False      # cudnn 사용 해제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieRL-cJ-2stM"
      },
      "source": [
        "Step 2-2.GPU 장비 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCyRsU3I2wAc"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHoQK0Vw5UWP"
      },
      "source": [
        "# STEP 3. Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv-BeF_h1rap"
      },
      "source": [
        "Step 3-1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4jMESbH5T7X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터 경로\n",
        "data_path = '/content/chest_xray/'\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터 경로 설정\n",
        "train_path = data_path + 'train/'\n",
        "valid_path = data_path + 'val/'\n",
        "test_path = data_path + 'test/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OR2BLnm3IKM"
      },
      "source": [
        "Step 3-2. Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms as T\n",
        "\n",
        "# 훈련 데이터용 변환기\n",
        "transform_train = T.Compose([\n",
        "    T.CenterCrop(180),            # 중앙 이미지 확대\n",
        "    T.RandomHorizontalFlip(0.5),  # 좌우 대칭\n",
        "    T.RandomVerticalFlip(0.2),    # 상하 대칭\n",
        "    T.RandomRotation(20),         # 이미지 회전\n",
        "    T.ToTensor(),                 # 텐서 객체로 변환\n",
        "    T.Normalize((0.485, 0.456, 0.406),\n",
        "                (0.229, 0.224, 0.225))])  # 정규화\n",
        "\n",
        "# 테스트 데이터용 변환기\n",
        "transform_test = T.Compose([\n",
        "    T.Resize((250, 250)),\n",
        "    T.CenterCrop(180),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.485, 0.456, 0.406),\n",
        "                (0.229, .224, 0.225))])"
      ],
      "metadata": {
        "id": "jJTsLaUHNFyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFTWbgSa1p7Z"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# 훈련 데이터셋\n",
        "dataset_train = ImageFolder(root=train_path, transform=transform_train)\n",
        "# 검증 데이터셋\n",
        "dataset_valid = ImageFolder(root=valid_path, transform=transform_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZtaJBsW3LUJ"
      },
      "source": [
        "Step 3-3. Dataloader(multiprocess)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 멀티프로세서 사용 시 데이터 로더 시드 고정\n",
        "def seed_worker(worker_id):\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(0)"
      ],
      "metadata": {
        "id": "MLqKi_yyyiK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-lUSwZJ1qVJ"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader # 데이터 로더 클래스\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "loader_train = DataLoader(dataset=dataset_train, batch_size=batch_size,\n",
        "                          shuffle=True, worker_init_fn=seed_worker,\n",
        "                          generator=g, num_workers=2)\n",
        "loader_valid = DataLoader(dataset=dataset_valid, batch_size=batch_size,\n",
        "                          shuffle=False, worker_init_fn=seed_worker,\n",
        "                          generator=g, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPv6ybM8zJYk"
      },
      "source": [
        "# STEP 4. Module\n",
        "### ★Improvement: Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4-1. Pretrained Model Load + ★Improvement: Ensemble"
      ],
      "metadata": {
        "id": "0h6jqMqpzfvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_list = [] # ★ 모델 저장용 리스트"
      ],
      "metadata": {
        "id": "83gl1jpHnHGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from efficientnet_pytorch import EfficientNet # EfficientNet 모듈\n",
        "\n",
        "# ★\n",
        "# 사전 훈련된 'efficientnet' 모델 불러오기\n",
        "efficientnet_b1 = EfficientNet.from_pretrained('efficientnet-b1', num_classes=2)  # num_classes : 최종 출력 갯수\n",
        "efficientnet_b2 = EfficientNet.from_pretrained('efficientnet-b2', num_classes=2)\n",
        "efficientnet_b3 = EfficientNet.from_pretrained('efficientnet-b3', num_classes=2)\n",
        "\n",
        "# ★\n",
        "# 장비 할당\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "efficientnet_b1 = efficientnet_b1.to(device)\n",
        "efficientnet_b2 = efficientnet_b2.to(device)\n",
        "efficientnet_b3 = efficientnet_b3.to(device)\n",
        "\n",
        "# ★\n",
        "# 리스트에 모델 저장\n",
        "models_list.append(efficientnet_b1)\n",
        "models_list.append(efficientnet_b2)\n",
        "models_list.append(efficientnet_b3)"
      ],
      "metadata": {
        "id": "oN90O7mazi9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, model in enumerate(models_list):\n",
        "  num_parmas = sum(param.numel() for param in model.parameters())\n",
        "  print(f\"모델{idx+1} 파라미터 갯수: {num_parmas}\")"
      ],
      "metadata": {
        "id": "TrHpEOaFnuvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa9kBj02zz7m"
      },
      "source": [
        "# STEP 5. Learning and Validation\n",
        "### ★Improvement: Optimizer, Scheduler, Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg8ZCYcJ0JIz"
      },
      "source": [
        "Step 5-1. Setting + ★Improvement: Optimizer, Scheduler, Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B8clGgz65sxJ"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.optim.adamw import AdamW\n",
        "\n",
        "#device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#model = model.to(device)\n",
        "#model = nn.DataParallel(model)       # 병렬 GPU 사용\n",
        "\n",
        "# 손실 함수\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# ★ 옵티마이저\n",
        "optimizer1 = AdamW(models_list[0].parameters(), lr=0.0006, weight_decay=0.001)\n",
        "optimizer2 = AdamW(models_list[1].parameters(), lr=0.0006, weight_decay=0.001)\n",
        "optimizer3 = AdamW(models_list[2].parameters(), lr=0.0006, weight_decay=0.001)\n",
        "\n",
        "# ★ Scheduler\n",
        "epochs = 5\n",
        "from transformers import get_cosine_schedule_with_warmup\n",
        "scheduler1 = get_cosine_schedule_with_warmup(optimizer1, num_warmup_steps=len(loader_train)*3,\n",
        "                                             num_training_steps=len(loader_train)*epochs)\n",
        "scheduler2 = get_cosine_schedule_with_warmup(optimizer2, num_warmup_steps=len(loader_train)*3,\n",
        "                                             num_training_steps=len(loader_train)*epochs)\n",
        "scheduler3 = get_cosine_schedule_with_warmup(optimizer3, num_warmup_steps=len(loader_train)*3,\n",
        "                                             num_training_steps=len(loader_train)*epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH9EvJSJz-AX"
      },
      "source": [
        "Step 5-2. Learning Function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, f1_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train(model, loader_train, loader_valid, criterion, optimizer,\n",
        "          scheduler=None, epochs=10, save_file='model_state_dic.pth'):\n",
        "  valid_loss_min = np.inf # 최소 손실값 초기화(검증데이터용)\n",
        "\n",
        "  # 총 에폭만큼 반복\n",
        "  for epoch in range(epochs):\n",
        "    print(f\"에폭 [{epoch + 1}/{epochs}] \\n-------------------------\")\n",
        "\n",
        "    # == [훈련] ================================\n",
        "    model.train()         # 모델을 훈련 상태로 설정\n",
        "    epoch_train_loss = 0  # 에폭별 손실값 초기화(훈련 데이터용)\n",
        "\n",
        "    # 반복 횟수 만큼 반복\n",
        "    for images, labels in tqdm(loader_train):\n",
        "      # 이미지, 레이블 데이터 미니배치를 장비 할당\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      optimizer.zero_grad()       # 기출기 초기화\n",
        "      outputs = model(images) # 순전파\n",
        "      loss = criterion(outputs, labels)   # 손실값 계산(훈련 데이터용)\n",
        "      epoch_train_loss += loss.item()     # 현재 배치에서의 손실 추가\n",
        "      loss.backward()         # 역전파\n",
        "      optimizer.step()            # 가중치 갱신\n",
        "\n",
        "      if scheduler != None:   # 스케줄러 학습률 갱신\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "    print(f\"\\t훈련 데이터 손실값: {epoch_train_loss/len(loader_train):.4f}\")\n",
        "\n",
        "\n",
        "    # == [검증] ================================\n",
        "    model.eval()    # 모델을 평가 상태로 설정\n",
        "    epoch_valid_loss = 0  # 에폭별 손실값 초기화(검증데이터용)\n",
        "    preds_list = [] # 에측값 저장용 리스트\n",
        "    true_list = []  # 실제값 저장용 리스트\n",
        "\n",
        "    with torch.no_grad(): # 기울기 계산 비활성화\n",
        "      # 미니 배치 단위로 검증\n",
        "      for images, labels in loader_valid:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)           # 순전파\n",
        "        loss = criterion(outputs, labels) # 손실값 계산(검증 데이터용)\n",
        "        epoch_valid_loss += loss.item()   # 현재 배치에서의 손실 추가\n",
        "\n",
        "        # 예측값 및 실제값\n",
        "        preds = torch.max(outputs.cpu(), dim=1)[1].numpy()  # torch.max[1]은 최대값의 열(0 or 1)을 반환\n",
        "        true = labels.cpu().numpy()\n",
        "\n",
        "        preds_list.extend(preds)\n",
        "        true_list.extend(true)\n",
        "\n",
        "    # 현재 에폭의 검증 완료\n",
        "    print(f\"\\t검증 데이터 손실값: {epoch_valid_loss/len(loader_valid):.4f}\")\n",
        "\n",
        "    # 평가지표 계산(정확도, 재현율, F1 점수)\n",
        "    val_accuracy = accuracy_score(true_list, preds_list)\n",
        "    val_recall = recall_score(true_list, preds_list)\n",
        "    val_f1_score = f1_score(true_list, preds_list)\n",
        "    print(f\"\\t정확도: {val_accuracy:.4f} / 재현율: {val_recall:.4f} / F1 점수: {val_f1_score:.4f}\")\n",
        "\n",
        "    # == [최적 모델 가중치 찾기] ===============\n",
        "    # 현 에폭에서의 손실값이 최소 손실값 이하면 모델 가중치 저장\n",
        "    if epoch_valid_loss <= valid_loss_min:\n",
        "      print(f\"\\t### 검증 데이터 손실값 감소 ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). 모델 저장\")\n",
        "\n",
        "      # 모델 가중치를 파일로 저장\n",
        "      torch.save(model.state_dict(), save_file)\n",
        "      valid_loss_min = epoch_valid_loss # 최소 손실값 갱신\n",
        "\n",
        "  return torch.load(save_file)  # 최적 모델 가중치 반환"
      ],
      "metadata": {
        "id": "h71o-VItQjUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5-3. Learning ★Improvement: Ensemble"
      ],
      "metadata": {
        "id": "N1F3uXX1WSrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 모델 훈련\n",
        "model_state_dict = train(model=models_list[0],\n",
        "                         loader_train=loader_train,\n",
        "                         loader_valid=loader_valid,\n",
        "                         criterion=criterion,\n",
        "                         optimizer=optimizer1,\n",
        "                         scheduler=scheduler1,\n",
        "                         epochs=epochs)\n",
        "# 첫 번째 모델에 최적 가중치 적용\n",
        "models_list[0].load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gP38aaoNWTy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 두 번째 모델 훈련\n",
        "model_state_dict = train(model=models_list[1],\n",
        "                         loader_train=loader_train,\n",
        "                         loader_valid=loader_valid,\n",
        "                         criterion=criterion,\n",
        "                         optimizer=optimizer2,\n",
        "                         scheduler=scheduler2,\n",
        "                         epochs=epochs)\n",
        "# 두 번째 모델에 최적 가중치 적용\n",
        "models_list[1].load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "id": "CfibQWubpoBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 세 번째 모델 훈련\n",
        "model_state_dict = train(model=models_list[2],\n",
        "                         loader_train=loader_train,\n",
        "                         loader_valid=loader_valid,\n",
        "                         criterion=criterion,\n",
        "                         optimizer=optimizer3,\n",
        "                         scheduler=scheduler3,\n",
        "                         epochs=epochs)\n",
        "# 세 번째 모델에 최적 가중치 적용\n",
        "models_list[2].load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "id": "H7LCi-2rpoOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TzxvoFCAZT7"
      },
      "source": [
        "# STEP 6. Evaluation and Submission\n",
        "### ★Improvement: Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4NkzUqjFMv0"
      },
      "source": [
        "Step 6-1. Setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs7stCVDFKcY"
      },
      "outputs": [],
      "source": [
        "dataset_test = ImageFolder(root=test_path, transform=transform_test)\n",
        "\n",
        "loader_test = DataLoader(dataset=dataset_test, batch_size=batch_size,\n",
        "                         shuffle=False, worker_init_fn=seed_worker,\n",
        "                         generator=g, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6-2. Predict Function"
      ],
      "metadata": {
        "id": "uGUv0_A5XDlo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, loader_test, return_true=False):\n",
        "  model.eval()    # 모델을 평가 상태로 설정\n",
        "  preds_list = [] # 예측값 저장용 리스트 초기화\n",
        "  true_list = []  # 실제값 저장용 리스트 초기화\n",
        "\n",
        "  with torch.no_grad(): # 기울기 계산 비활성화\n",
        "    for images, labels in loader_test:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(images)\n",
        "\n",
        "      preds = torch.max(outputs.cpu(), dim=1)[1].numpy()  # 예측값\n",
        "      true = labels.cpu().numpy()                         # 실제값\n",
        "\n",
        "      preds_list.extend(preds)\n",
        "      true_list.extend(true)\n",
        "\n",
        "    if return_true:\n",
        "      return true_list, preds_list\n",
        "    else:\n",
        "      return preds_list"
      ],
      "metadata": {
        "id": "4rAoTfknXDMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K8oHdB4FZZU"
      },
      "source": [
        "Step 7-3. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_lists = []\n",
        "true_list, preds_lists[0] = predict(model=models_list[0],\n",
        "                                loader_test=loader_test,\n",
        "                                return_true=True)\n",
        "\n",
        "preds_lists[1] = predict(model=models_list[1],\n",
        "                      loader_test=loader_test)\n",
        "\n",
        "preds_lists[2] = predict(model=models_list[2],\n",
        "                      loader_test=loader_test)"
      ],
      "metadata": {
        "id": "6K3doIZiYKcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4RI5dL7FOQL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for idx, preds_list in enumerate(preds_lists):\n",
        "  print(\"#\"*5, f\"모델 efficientnet-b{idx+1} 예측 결과 평가 점수\", \"#*5\")\n",
        "  print(f\"정확도: {accuracy_score(true_list, preds_list):.4f}\")\n",
        "  print(f\"재현율: {recall_score(true_list, preds_list):.4f}\")\n",
        "  print(f\"F1 점수: {f1_score(true_list, preds_list):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7-4. ★Ensemble"
      ],
      "metadata": {
        "id": "VUxKwIKKrb7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_preds = []\n",
        "\n",
        "for i in range(len(preds_lists[0])):\n",
        "  pred_element = np.round((preds_lists[0][i] + preds_lists[1][i] + preds_lists[2][i])/3) # 예측값 더하고 3으로 나눈뒤 반올림(과반수)\n",
        "  ensemble_preds.append(pred_element)"
      ],
      "metadata": {
        "id": "_teYl2fnrf9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"#\"*5, f\"앙상블 예측 결과 평가 점수\", \"#*5\")\n",
        "print(f\"정확도: {accuracy_score(true_list, ensemble_preds):.4f}\")\n",
        "print(f\"재현율: {recall_score(true_list, ensemble_preds):.4f}\")\n",
        "print(f\"F1 점수: {f1_score(true_list, ensemble_preds):.4f}\")"
      ],
      "metadata": {
        "id": "bO0fqsj9sEoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrKX3dBvF5Ib"
      },
      "source": [
        "Step 7-5. Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7NJo_4fF6U-"
      },
      "outputs": [],
      "source": [
        "# submission[['healthy', 'multiple_diseases', 'rust', 'scab']] = preds   # submission df 결과값 재설정\n",
        "# submission.to_csv('submission.csv', index=False)                       # 제출 파일 생성\n",
        "\n",
        "# # 이미지 테스트 데이터 삭제\n",
        "# import shutil\n",
        "\n",
        "# shutil.rmtree('./train')\n",
        "# shutil.rmtree('./test')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}